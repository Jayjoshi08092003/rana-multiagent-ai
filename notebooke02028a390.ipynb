{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install triton\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:38:46.793228Z","iopub.execute_input":"2025-09-07T12:38:46.793499Z","iopub.status.idle":"2025-09-07T12:38:52.669638Z","shell.execute_reply.started":"2025-09-07T12:38:46.793455Z","shell.execute_reply":"2025-09-07T12:38:52.668872Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (3.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# =====================================================\n# Adaptive Depth Forward (Kaggle-friendly with Triton fallback)\n# =====================================================\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Try Triton import\nUSE_TRITON = False\ntry:\n    import triton\n    import triton.language as tl\n    USE_TRITON = True\n    print(\"✅ Triton available, will use fused kernel.\")\nexcept Exception as e:\n    print(\"⚠️ Triton not available, falling back to PyTorch implementation.\")\n\n# -------------------------------\n# Simple PyTorch Grouped baseline\n# -------------------------------\ndef adaptive_forward_grouped(model, x, depths):\n    \"\"\"\n    Reference grouped implementation.\n    model: has .encoder and .core_blocks\n    x: [B, C, H, W]\n    depths: [B] ints\n    \"\"\"\n    device = x.device\n    depths_sorted, perm = depths.sort()\n    x_sorted = x[perm]\n    h = model.encoder(x_sorted)\n    outputs_sorted_h = torch.zeros_like(h)\n    unique_depths, counts = torch.unique_consecutive(depths_sorted, return_counts=True)\n    start = 0\n    for depth_val, cnt in zip(unique_depths.tolist(), counts.tolist()):\n        end = start + cnt\n        h_group = h[start:end]\n        for d in range(depth_val):\n            h_group = model.core_blocks[d](h_group)\n        outputs_sorted_h[start:end] = h_group\n        start = end\n    _, inv_perm = perm.sort()\n    return outputs_sorted_h[inv_perm]\n\n# -------------------------------\n# Triton fused kernel (optional)\n# -------------------------------\nif USE_TRITON:\n    BLOCK = 64  # tune based on hidden dim\n\n    @triton.jit\n    def _phase1_w1_matvec(\n        h_ptr, out1_ptr, W1_ptr, b1_ptr,\n        B, H, d,\n        stride_h_batch, stride_h_hidden,\n        stride_w_depth, stride_w_row, stride_w_col,\n        stride_b_depth, stride_b_col,\n        BLOCK: tl.constexpr\n    ):\n        batch_idx = tl.program_id(0)\n        tile_idx = tl.program_id(1)\n        col_start = tile_idx * BLOCK\n        hid_offsets = col_start + tl.arange(0, BLOCK)\n        h_offsets = batch_idx * stride_h_batch + hid_offsets\n        h_vec = tl.load(h_ptr + h_offsets, mask=hid_offsets < H, other=0.0)\n\n        out1 = tl.zeros([BLOCK], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            h_col_offsets = batch_idx * stride_h_batch + c_start + tl.arange(0, BLOCK)\n            h_col = tl.load(h_ptr + h_col_offsets, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w1_row_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w1_offsets = w1_row_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            W1_tile = tl.load(W1_ptr + w1_offsets.reshape(-1), mask=True, other=0.0).reshape(BLOCK, BLOCK)\n            out1 = out1 + tl.sum(W1_tile * h_col[None, :], axis=1)\n\n        b1_offsets = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b1_tile = tl.load(b1_ptr + b1_offsets, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out1 = tl.maximum(out1 + b1_tile, 0.0)\n\n        out1_offsets = batch_idx * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out1_ptr + out1_offsets, out1, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    # You’d add a phase2 kernel for W2 here (similar idea) …\n    # For Kaggle demo, we’ll just show phase1 to illustrate that Triton compiles.\n\n    def adaptive_forward_triton(h, depths, W1, b1):\n        # stub: just calls phase1 once\n        B, H = h.shape\n        out1 = torch.empty_like(h)\n        grid = (B, (H + BLOCK - 1) // BLOCK)\n        stride_h_batch = H\n        stride_h_hidden = 1\n        stride_w_depth, stride_w_row, stride_w_col = W1.stride()\n        stride_b_depth, stride_b_col = b1.stride()\n\n        _phase1_w1_matvec[grid](\n            h, out1, W1, b1,\n            B, H, 0,\n            stride_h_batch, stride_h_hidden,\n            stride_w_depth, stride_w_row, stride_w_col,\n            stride_b_depth, stride_b_col,\n            BLOCK=BLOCK\n        )\n        return out1\n\n# -------------------------------\n# Safe wrapper for Kaggle\n# -------------------------------\ndef adaptive_forward(model, x, depths, W1=None, b1=None):\n    if USE_TRITON and W1 is not None:\n        try:\n            return adaptive_forward_triton(x, depths, W1, b1)\n        except Exception as e:\n            print(\"⚠️ Triton kernel failed, using PyTorch fallback.\", e)\n            return adaptive_forward_grouped(model, x, depths)\n    else:\n        return adaptive_forward_grouped(model, x, depths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:38:56.173174Z","iopub.execute_input":"2025-09-07T12:38:56.173920Z","iopub.status.idle":"2025-09-07T12:39:04.247453Z","shell.execute_reply.started":"2025-09-07T12:38:56.173884Z","shell.execute_reply":"2025-09-07T12:39:04.246723Z"}},"outputs":[{"name":"stdout","text":"✅ Triton available, will use fused kernel.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"\n# =====================================================\n# Adaptive Depth Forward (Kaggle-friendly with Triton fallback)\n# =====================================================\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# -------------------------------\n# Triton availability check\n# -------------------------------\nUSE_TRITON = False\ntry:\n    import triton\n    import triton.language as tl\n    USE_TRITON = True\n    print(\"✅ Triton available, will use fused kernel.\")\nexcept Exception as e:\n    print(\"⚠️ Triton not available, falling back to PyTorch implementation.\")\n\n# -------------------------------\n# PyTorch grouped baseline\n# -------------------------------\ndef adaptive_forward_grouped(model, x, depths):\n    \"\"\"\n    Grouped reference implementation.\n    model: has .encoder and .core_blocks\n    x: [B, C, H, W]\n    depths: [B] ints\n    \"\"\"\n    device = x.device\n    depths_sorted, perm = depths.sort()\n    x_sorted = x[perm]\n    h = model.encoder(x_sorted)\n    outputs_sorted_h = torch.zeros_like(h)\n    unique_depths, counts = torch.unique_consecutive(depths_sorted, return_counts=True)\n    start = 0\n    for depth_val, cnt in zip(unique_depths.tolist(), counts.tolist()):\n        end = start + cnt\n        h_group = h[start:end]\n        for d in range(depth_val):\n            h_group = model.core_blocks[d](h_group)\n        outputs_sorted_h[start:end] = h_group\n        start = end\n    _, inv_perm = perm.sort()\n    return outputs_sorted_h[inv_perm]\n\n# -------------------------------\n# Triton fused kernel (optional)\n# -------------------------------\nif USE_TRITON:\n    BLOCK = 64  # tune based on hidden dim\n\n    @triton.jit\n    def _phase1_w1_matvec(\n        h_ptr, out1_ptr, W1_ptr, b1_ptr,\n        B, H, d,\n        stride_h_batch, stride_h_hidden,\n        stride_w_depth, stride_w_row, stride_w_col,\n        stride_b_depth, stride_b_col,\n        BLOCK: tl.constexpr\n    ):\n        batch_idx = tl.program_id(0)\n        tile_idx = tl.program_id(1)\n        col_start = tile_idx * BLOCK\n        hid_offsets = col_start + tl.arange(0, BLOCK)\n        h_offsets = batch_idx * stride_h_batch + hid_offsets\n        h_vec = tl.load(h_ptr + h_offsets, mask=hid_offsets < H, other=0.0)\n\n        out1 = tl.zeros([BLOCK], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            h_col_offsets = batch_idx * stride_h_batch + c_start + tl.arange(0, BLOCK)\n            h_col = tl.load(h_ptr + h_col_offsets, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w1_row_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w1_offsets = w1_row_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            W1_tile = tl.load(W1_ptr + w1_offsets.reshape(-1), mask=True, other=0.0).reshape(BLOCK, BLOCK)\n            out1 = out1 + tl.sum(W1_tile * h_col[None, :], axis=1)\n\n        b1_offsets = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b1_tile = tl.load(b1_ptr + b1_offsets, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out1 = tl.maximum(out1 + b1_tile, 0.0)\n\n        out1_offsets = batch_idx * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out1_ptr + out1_offsets, out1, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    def adaptive_forward_triton(h, depths, W1, b1):\n        \"\"\"\n        Simple Triton version for illustration.\n        In practice, you would add more phases for full adaptive depth.\n        \"\"\"\n        B, H = h.shape\n        out1 = torch.empty_like(h)\n        grid = (B, (H + BLOCK - 1) // BLOCK)\n        stride_h_batch = H\n        stride_h_hidden = 1\n        stride_w_depth, stride_w_row, stride_w_col = W1.stride()\n        stride_b_depth, stride_b_col = b1.stride()\n\n        _phase1_w1_matvec[grid](\n            h, out1, W1, b1,\n            B, H, 0,\n            stride_h_batch, stride_h_hidden,\n            stride_w_depth, stride_w_row, stride_w_col,\n            stride_b_depth, stride_b_col,\n            BLOCK=BLOCK\n        )\n        return out1\n\n# -------------------------------\n# Unified wrapper for Kaggle\n# -------------------------------\ndef adaptive_forward(model, x, depths, W1=None, b1=None):\n    if USE_TRITON and W1 is not None:\n        try:\n            return adaptive_forward_triton(x, depths, W1, b1)\n        except Exception as e:\n            print(\"⚠️ Triton kernel failed, using PyTorch fallback.\", e)\n            return adaptive_forward_grouped(model, x, depths)\n    else:\n        return adaptive_forward_grouped(model, x, depths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:42:33.748348Z","iopub.execute_input":"2025-09-07T12:42:33.749034Z","iopub.status.idle":"2025-09-07T12:42:33.766690Z","shell.execute_reply.started":"2025-09-07T12:42:33.749009Z","shell.execute_reply":"2025-09-07T12:42:33.765961Z"}},"outputs":[{"name":"stdout","text":"✅ Triton available, will use fused kernel.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# =====================================================\n# Kaggle-safe Adaptive Forward with Triton (phase1+phase2)\n# =====================================================\n\nimport torch\n\nif USE_TRITON:\n    BLOCK = 32  # safe default for small hidden dims\n\n    @triton.jit\n    def _phase1_w1_matvec_safe(\n        h_ptr, out1_ptr, W1_ptr, b1_ptr,\n        B, H, d,\n        stride_h_batch, stride_h_hidden,\n        stride_w_depth, stride_w_row, stride_w_col,\n        stride_b_depth, stride_b_col,\n        BLOCK: tl.constexpr\n    ):\n        pid_b = tl.program_id(0)\n        pid_col = tl.program_id(1)\n        col_start = pid_col * BLOCK\n        offsets = col_start + tl.arange(0, BLOCK)\n        h_off = pid_b * stride_h_batch + offsets\n        h_vec = tl.load(h_ptr + h_off, mask=offsets < H, other=0.0)\n\n        out = tl.zeros([BLOCK], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            h_col_off = pid_b * stride_h_batch + c_start + tl.arange(0, BLOCK)\n            h_col = tl.load(h_ptr + h_col_off, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w_off_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w_off = w_off_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            W_tile = tl.load(W1_ptr + w_off.reshape(-1), mask=True, other=0.0).reshape(BLOCK, BLOCK)\n            out += tl.sum(W_tile * h_col[None, :], axis=1)\n\n        b_off = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b_tile = tl.load(b1_ptr + b_off, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out = tl.maximum(out + b_tile, 0.0)\n\n        out_off = pid_b * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out1_ptr + out_off, out, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    @triton.jit\n    def _phase2_w2_matvec_safe(\n        out1_ptr, out2_ptr, W2_ptr, b2_ptr,\n        B, H, d,\n        stride_out1_batch, stride_out1_hidden,\n        stride_w_depth, stride_w_row, stride_w_col,\n        stride_b_depth, stride_b_col,\n        BLOCK: tl.constexpr\n    ):\n        pid_b = tl.program_id(0)\n        pid_col = tl.program_id(1)\n        col_start = pid_col * BLOCK\n        offsets = col_start + tl.arange(0, BLOCK)\n        out1_off = pid_b * stride_out1_batch + offsets\n        out1_vec = tl.load(out1_ptr + out1_off, mask=offsets < H, other=0.0)\n\n        out = tl.zeros([BLOCK], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            out1_col_off = pid_b * stride_out1_batch + c_start + tl.arange(0, BLOCK)\n            out1_col = tl.load(out1_ptr + out1_col_off, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w_off_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w_off = w_off_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            W_tile = tl.load(W2_ptr + w_off.reshape(-1), mask=True, other=0.0).reshape(BLOCK, BLOCK)\n            out += tl.sum(W_tile * out1_col[None, :], axis=1)\n\n        b_off = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b_tile = tl.load(b2_ptr + b_off, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out += b_tile\n\n        out_off = pid_b * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out2_ptr + out_off, out, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    # -------------------------------\n    # Safe adaptive forward wrapper\n    # -------------------------------\n    def adaptive_forward_triton_safe(h, depths, W1, b1, W2, b2):\n        # Ensure CUDA and contiguous\n        h = h.contiguous().cuda()\n        W1, b1 = W1.contiguous().cuda(), b1.contiguous().cuda()\n        W2, b2 = W2.contiguous().cuda(), b2.contiguous().cuda()\n\n        B, H = h.shape\n        out1 = torch.empty_like(h)\n        out2 = torch.empty_like(h)\n        grid = (B, (H + BLOCK - 1) // BLOCK)\n\n        # Phase 1\n        stride_h_batch = H\n        stride_h_hidden = 1\n        stride_w_depth, stride_w_row, stride_w_col = W1.stride()\n        stride_b_depth, stride_b_col = b1.stride()\n\n        _phase1_w1_matvec_safe[grid](\n            h, out1, W1, b1,\n            B, H, 0,\n            stride_h_batch, stride_h_hidden,\n            stride_w_depth, stride_w_row, stride_w_col,\n            stride_b_depth, stride_b_col,\n            BLOCK=BLOCK\n        )\n\n        # Phase 2\n        stride_out1_batch = H\n        stride_out1_hidden = 1\n        stride_w_depth2, stride_w_row2, stride_w_col2 = W2.stride()\n        stride_b_depth2, stride_b_col2 = b2.stride()\n\n        _phase2_w2_matvec_safe[grid](\n            out1, out2, W2, b2,\n            B, H, 0,\n            stride_out1_batch, stride_out1_hidden,\n            stride_w_depth2, stride_w_row2, stride_w_col2,\n            stride_b_depth2, stride_b_col2,\n            BLOCK=BLOCK\n        )\n\n        return out2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:44:58.266708Z","iopub.execute_input":"2025-09-07T12:44:58.267014Z","iopub.status.idle":"2025-09-07T12:44:58.286834Z","shell.execute_reply.started":"2025-09-07T12:44:58.266991Z","shell.execute_reply":"2025-09-07T12:44:58.286166Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if USE_TRITON:\n    BLOCK = 64  # tune based on hidden dim\n\n    # Phase 1: h @ W1 + b1 + ReLU\n    @triton.jit\n    def _phase1_w1_matvec(\n        h_ptr, out1_ptr, W1_ptr, b1_ptr,\n        B, H, d,\n        stride_h_batch, stride_h_hidden,\n        stride_w_depth, stride_w_row, stride_w_col,\n        stride_b_depth, stride_b_col,\n        BLOCK: tl.constexpr\n    ):\n        batch_idx = tl.program_id(0)\n        tile_idx = tl.program_id(1)\n        col_start = tile_idx * BLOCK\n        hid_offsets = col_start + tl.arange(0, BLOCK)\n        h_offsets = batch_idx * stride_h_batch + hid_offsets\n        h_vec = tl.load(h_ptr + h_offsets, mask=hid_offsets < H, other=0.0)\n\n        out1 = tl.zeros([BLOCK], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            h_col_offsets = batch_idx * stride_h_batch + c_start + tl.arange(0, BLOCK)\n            h_col = tl.load(h_ptr + h_col_offsets, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w1_row_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w1_offsets = w1_row_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            W1_tile = tl.load(W1_ptr + w1_offsets.reshape(-1), mask=True, other=0.0).reshape(BLOCK, BLOCK)\n            out1 = out1 + tl.sum(W1_tile * h_col[None, :], axis=1)\n\n        b1_offsets = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b1_tile = tl.load(b1_ptr + b1_offsets, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out1 = tl.maximum(out1 + b1_tile, 0.0)\n\n        out1_offsets = batch_idx * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out1_ptr + out1_offsets, out1, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    # Phase 2: out1 @ W2 + b2 (no ReLU if last layer)\n    @triton.jit\n    def _phase2_w2_matvec(\n        out1_ptr, out2_ptr, W2_ptr, b2_ptr,\n        B, H, d,\n        stride_out1_batch, stride_out1_hidden,\n        stride_w_depth, stride_w_row, stride_w_col,\n        stride_b_depth, stride_b_col,\n        BLOCK: tl.constexpr\n    ):\n        batch_idx = tl.program_id(0)\n        tile_idx = tl.program_id(1)\n        col_start = tile_idx * BLOCK\n        hid_offsets = col_start + tl.arange(0, BLOCK)\n        out1_offsets = batch_idx * stride_out1_batch + hid_offsets\n        out1_vec = tl.load(out1_ptr + out1_offsets, mask=hid_offsets < H, other=0.0)\n\n        out2 = tl.zeros([BLOCK], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            out1_col_offsets = batch_idx * stride_out1_batch + c_start + tl.arange(0, BLOCK)\n            out1_col = tl.load(out1_ptr + out1_col_offsets, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w2_row_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w2_offsets = w2_row_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            W2_tile = tl.load(W2_ptr + w2_offsets.reshape(-1), mask=True, other=0.0).reshape(BLOCK, BLOCK)\n            out2 = out2 + tl.sum(W2_tile * out1_col[None, :], axis=1)\n\n        b2_offsets = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b2_tile = tl.load(b2_ptr + b2_offsets, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out2 = out2 + b2_tile  # usually no ReLU if last layer\n\n        out2_offsets = batch_idx * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out2_ptr + out2_offsets, out2, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    # Updated adaptive forward with both phases\n    def adaptive_forward_triton(h, depths, W1, b1, W2, b2):\n        B, H = h.shape\n        out1 = torch.empty_like(h)\n        out2 = torch.empty_like(h)\n        grid = (B, (H + BLOCK - 1) // BLOCK)\n\n        # Phase 1\n        stride_h_batch = H\n        stride_h_hidden = 1\n        stride_w_depth, stride_w_row, stride_w_col = W1.stride()\n        stride_b_depth, stride_b_col = b1.stride()\n\n        _phase1_w1_matvec[grid](\n            h, out1, W1, b1,\n            B, H, 0,\n            stride_h_batch, stride_h_hidden,\n            stride_w_depth, stride_w_row, stride_w_col,\n            stride_b_depth, stride_b_col,\n            BLOCK=BLOCK\n        )\n\n        # Phase 2\n        stride_out1_batch = H\n        stride_out1_hidden = 1\n        stride_w_depth2, stride_w_row2, stride_w_col2 = W2.stride()\n        stride_b_depth2, stride_b_col2 = b2.stride()\n\n        _phase2_w2_matvec[grid](\n            out1, out2, W2, b2,\n            B, H, 0,\n            stride_out1_batch, stride_out1_hidden,\n            stride_w_depth2, stride_w_row2, stride_w_col2,\n            stride_b_depth2, stride_b_col2,\n            BLOCK=BLOCK\n        )\n\n        return out2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# -------------------------------\n# Dummy model for PyTorch fallback\n# -------------------------------\nclass DummyModel:\n    def __init__(self, hidden_dim, num_blocks):\n        self.encoder = nn.Identity()\n        self.core_blocks = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(num_blocks)])\n        \nhidden_dim = 8\nnum_blocks = 2\nmodel = DummyModel(hidden_dim, num_blocks)\n\n# -------------------------------\n# Dummy input\n# -------------------------------\nB = 3\nx = torch.randn(B, hidden_dim, device='cuda' if USE_TRITON else 'cpu')\ndepths = torch.tensor([1, 2, 1], device=x.device)\n\n# -------------------------------\n# Dummy Triton weights (optional)\n# -------------------------------\nif USE_TRITON:\n    W1 = torch.randn(1, hidden_dim, hidden_dim, device='cuda')\n    b1 = torch.randn(1, hidden_dim, device='cuda')\n    W2 = torch.randn(1, hidden_dim, hidden_dim, device='cuda')\n    b2 = torch.randn(1, hidden_dim, device='cuda')\nelse:\n    W1 = b1 = W2 = b2 = None\n\n# -------------------------------\n# Run adaptive forward\n# -------------------------------\nout = adaptive_forward(model, x, depths, W1, b1, W2, b2)\nprint(\"Output shape:\", out.shape)\nprint(out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:46:08.994735Z","iopub.execute_input":"2025-09-07T12:46:08.995034Z","iopub.status.idle":"2025-09-07T12:46:09.404108Z","shell.execute_reply.started":"2025-09-07T12:46:08.995012Z","shell.execute_reply":"2025-09-07T12:46:09.402891Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3422531590.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Run adaptive forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# -------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madaptive_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Output shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: adaptive_forward() takes from 3 to 5 positional arguments but 7 were given"],"ename":"TypeError","evalue":"adaptive_forward() takes from 3 to 5 positional arguments but 7 were given","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"def adaptive_forward(model, x, depths, W1=None, b1=None, W2=None, b2=None):\n    \"\"\"\n    Adaptive depth forward pass with Triton fallback.\n\n    Args:\n        model: object with .encoder and .core_blocks\n        x: [B, C, H, W] input tensor\n        depths: [B] ints for adaptive depth\n        W1, b1, W2, b2: optional Triton linear weights & biases\n\n    Returns:\n        Tensor of shape [B, H, W] after adaptive depth processing\n    \"\"\"\n    # Use Triton only if available and all weights provided\n    if USE_TRITON and W1 is not None and W2 is not None:\n        try:\n            return adaptive_forward_triton_safe(x, depths, W1, b1, W2, b2)\n        except Exception as e:\n            print(\"⚠️ Triton kernel failed, falling back to PyTorch implementation:\", e)\n            return adaptive_forward_grouped(model, x, depths)\n    else:\n        # Default PyTorch grouped implementation\n        return adaptive_forward_grouped(model, x, depths)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T12:47:11.485378Z","iopub.execute_input":"2025-09-07T12:47:11.485851Z","iopub.status.idle":"2025-09-07T12:47:11.490253Z","shell.execute_reply.started":"2025-09-07T12:47:11.485829Z","shell.execute_reply":"2025-09-07T12:47:11.489590Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# =====================================================\n# Kaggle-ready Adaptive Depth Forward with Triton fallback (fixed)\n# =====================================================\n\nimport torch\nimport torch.nn as nn\n\n# -------------------------------\n# Triton availability\n# -------------------------------\nUSE_TRITON = False\ntry:\n    import triton\n    import triton.language as tl\n    USE_TRITON = True\n    print(\"✅ Triton available, will use fused kernel.\")\nexcept Exception as e:\n    print(\"⚠️ Triton not available, falling back to PyTorch implementation.\")\n\n# -------------------------------\n# PyTorch grouped baseline\n# -------------------------------\ndef adaptive_forward_grouped(model, x, depths):\n    device = x.device\n    depths_sorted, perm = depths.sort()\n    x_sorted = x[perm]\n    h = model.encoder(x_sorted)\n    outputs_sorted_h = torch.zeros_like(h)\n    unique_depths, counts = torch.unique_consecutive(depths_sorted, return_counts=True)\n    start = 0\n    for depth_val, cnt in zip(unique_depths.tolist(), counts.tolist()):\n        end = start + cnt\n        h_group = h[start:end]\n        for d in range(depth_val):\n            h_group = model.core_blocks[d](h_group)\n        outputs_sorted_h[start:end] = h_group\n        start = end\n    _, inv_perm = perm.sort()\n    return outputs_sorted_h[inv_perm]\n\n# -------------------------------\n# Triton fused kernels (phase1 + phase2)\n# -------------------------------\nif USE_TRITON:\n    BLOCK = 32  # safe default\n\n    @triton.jit\n    def _phase1_w1_matvec_safe(h_ptr, out1_ptr, W1_ptr, b1_ptr,\n                               B, H, d,\n                               stride_h_batch, stride_h_hidden,\n                               stride_w_depth, stride_w_row, stride_w_col,\n                               stride_b_depth, stride_b_col,\n                               BLOCK: tl.constexpr):\n        pid_b = tl.program_id(0)\n        pid_col = tl.program_id(1)\n        col_start = pid_col * BLOCK\n        offsets = col_start + tl.arange(0, BLOCK)\n        h_off = pid_b * stride_h_batch + offsets\n        h_vec = tl.load(h_ptr + h_off, mask=offsets < H, other=0.0)\n\n        out = tl.zeros([tl.minimum(BLOCK,H)], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            h_col_off = pid_b * stride_h_batch + c_start + tl.arange(0, BLOCK)\n            h_col = tl.load(h_ptr + h_col_off, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w_off_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w_off = w_off_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            mask_tile = (row_inds[:, None] < H) & (tl.arange(0, BLOCK)[None, :] < H)\n            W_tile = tl.load(W1_ptr + w_off.reshape(-1), mask=mask_tile.reshape(-1), other=0.0)\n            W_tile = W_tile.reshape(tl.minimum(BLOCK,H), tl.minimum(BLOCK,H))\n            out += tl.sum(W_tile * h_col[None, :tl.minimum(BLOCK,H)], axis=1)\n\n        b_off = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b_tile = tl.load(b1_ptr + b_off, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out = tl.maximum(out + b_tile[:tl.minimum(BLOCK,H)], 0.0)\n\n        out_off = pid_b * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out1_ptr + out_off, out, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    @triton.jit\n    def _phase2_w2_matvec_safe(out1_ptr, out2_ptr, W2_ptr, b2_ptr,\n                               B, H, d,\n                               stride_out1_batch, stride_out1_hidden,\n                               stride_w_depth, stride_w_row, stride_w_col,\n                               stride_b_depth, stride_b_col,\n                               BLOCK: tl.constexpr):\n        pid_b = tl.program_id(0)\n        pid_col = tl.program_id(1)\n        col_start = pid_col * BLOCK\n        offsets = col_start + tl.arange(0, BLOCK)\n        out1_off = pid_b * stride_out1_batch + offsets\n        out1_vec = tl.load(out1_ptr + out1_off, mask=offsets < H, other=0.0)\n\n        out = tl.zeros([tl.minimum(BLOCK,H)], dtype=tl.float32)\n        num_tiles = (H + BLOCK - 1) // BLOCK\n        for t in range(num_tiles):\n            c_start = t * BLOCK\n            out1_col_off = pid_b * stride_out1_batch + c_start + tl.arange(0, BLOCK)\n            out1_col = tl.load(out1_ptr + out1_col_off, mask=(c_start + tl.arange(0, BLOCK)) < H, other=0.0)\n\n            row_inds = col_start + tl.arange(0, BLOCK)\n            w_off_base = d * stride_w_depth + row_inds * stride_w_row + c_start * stride_w_col\n            w_off = w_off_base[:, None] + tl.arange(0, BLOCK)[None, :] * stride_w_col\n            mask_tile = (row_inds[:, None] < H) & (tl.arange(0, BLOCK)[None, :] < H)\n            W_tile = tl.load(W2_ptr + w_off.reshape(-1), mask=mask_tile.reshape(-1), other=0.0)\n            W_tile = W_tile.reshape(tl.minimum(BLOCK,H), tl.minimum(BLOCK,H))\n            out += tl.sum(W_tile * out1_col[None, :tl.minimum(BLOCK,H)], axis=1)\n\n        b_off = d * stride_b_depth + (col_start + tl.arange(0, BLOCK)) * stride_b_col\n        b_tile = tl.load(b2_ptr + b_off, mask=(col_start + tl.arange(0, BLOCK)) < H, other=0.0)\n        out += b_tile[:tl.minimum(BLOCK,H)]\n\n        out_off = pid_b * H + col_start + tl.arange(0, BLOCK)\n        tl.store(out2_ptr + out_off, out, mask=(col_start + tl.arange(0, BLOCK)) < H)\n\n    # -------------------------------\n    # Safe Triton wrapper\n    # -------------------------------\n    def adaptive_forward_triton_safe(h, depths, W1, b1, W2, b2):\n        device = h.device\n        h = h.contiguous().to(device)\n        W1, b1 = W1.contiguous().to(device), b1.contiguous().to(device)\n        W2, b2 = W2.contiguous().to(device), b2.contiguous().to(device)\n\n        B, H = h.shape\n        out1 = torch.empty_like(h)\n        out2 = torch.empty_like(h)\n        grid = (B, (H + BLOCK - 1) // BLOCK)\n\n        stride_h_batch = H\n        stride_h_hidden = 1\n        stride_w_depth, stride_w_row, stride_w_col = W1.stride()\n        stride_b_depth, stride_b_col = b1.stride()\n\n        _phase1_w1_matvec_safe[grid](h, out1, W1, b1,\n                                     B, H, 0,\n                                     stride_h_batch, stride_h_hidden,\n                                     stride_w_depth, stride_w_row, stride_w_col,\n                                     stride_b_depth, stride_b_col,\n                                     BLOCK=BLOCK)\n\n        stride_out1_batch = H\n        stride_out1_hidden = 1\n        stride_w_depth2, stride_w_row2, stride_w_col2 = W2.stride()\n        stride_b_depth2, stride_b_col2 = b2.stride()\n\n        _phase2_w2_matvec_safe[grid](out1, out2, W2, b2,\n                                     B, H, 0,\n                                     stride_out1_batch, stride_out1_hidden,\n                                     stride_w_depth2, stride_w_row2, stride_w_col2,\n                                     stride_b_depth2, stride_b_col2,\n                                     BLOCK=BLOCK)\n        return out2\n\n# -------------------------------\n# Unified Kaggle wrapper\n# -------------------------------\ndef adaptive_forward(model, x, depths, W1=None, b1=None, W2=None, b2=None):\n    device = x.device\n    model.encoder.to(device)\n    for block in model.core_blocks:\n        block.to(device)\n\n    if USE_TRITON and W1 is not None and W2 is not None:\n        try:\n            return adaptive_forward_triton_safe(x, depths, W1, b1, W2, b2)\n        except Exception as e:\n            print(\"⚠️ Triton kernel failed, falling back to PyTorch:\", e)\n            return adaptive_forward_grouped(model, x, depths)\n    else:\n        return adaptive_forward_grouped(model, x, depths)\n\n# -------------------------------\n# Test snippet\n# -------------------------------\nclass DummyModel:\n    def __init__(self, hidden_dim, num_blocks):\n        self.encoder = nn.Identity()\n        self.core_blocks = nn.ModuleList([nn.Linear(hidden_dim, hidden_dim) for _ in range(num_blocks)])\n\nhidden_dim = 8\nnum_blocks = 2\nmodel = DummyModel(hidden_dim, num_blocks)\n\nB = 3\nx = torch.randn(B, hidden_dim, device='cuda' if USE_TRITON else 'cpu')\ndepths = torch.tensor([1, 2, 1], device=x.device)\n\nif USE_TRITON:\n    W1 = torch.randn(1, hidden_dim, hidden_dim, device='cuda')\n    b1 = torch.randn(1, hidden_dim, device='cuda')\n    W2 = torch.randn(1, hidden_dim, hidden_dim, device='cuda')\n    b2 = torch.randn(1, hidden_dim, device='cuda')\nelse:\n    W1 = b1 = W2 = b2 = None\n\nout = adaptive_forward(model, x, depths, W1, b1, W2, b2)\nprint(\"Output shape:\", out.shape)\nprint(out)\n\n# -------------------------------\n# Consistency check: Triton vs PyTorch\n# -------------------------------\nif USE_TRITON:\n    out_pt = adaptive_forward_grouped(model, x, depths)\n    max_diff = (out_pt - out).abs().max().item()\n    mean_diff = (out_pt - out).abs().mean().item()\n    print(f\"Max absolute difference: {max_diff:.6f}\")\n    print(f\"Mean absolute difference: {mean_diff:.6f}\")\n    if max_diff < 1e-4:\n        print(\"✅ Triton output matches PyTorch output closely!\")\n    else:\n        print(\"⚠️ Triton output differs significantly from PyTorch output.\")\nelse:\n    print(\"Triton not available, skipping consistency check.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:02:03.180928Z","iopub.execute_input":"2025-09-07T13:02:03.181501Z","iopub.status.idle":"2025-09-07T13:02:04.066986Z","shell.execute_reply.started":"2025-09-07T13:02:03.181476Z","shell.execute_reply":"2025-09-07T13:02:04.066280Z"}},"outputs":[{"name":"stdout","text":"✅ Triton available, will use fused kernel.\n⚠️ Triton kernel failed, falling back to PyTorch: at 14:10:\n                           stride_h_batch, stride_h_hidden,\n                           stride_w_depth, stride_w_row, stride_w_col,\n                           stride_b_depth, stride_b_col,\n                           BLOCK: tl.constexpr):\n    pid_b = tl.program_id(0)\n    pid_col = tl.program_id(1)\n    col_start = pid_col * BLOCK\n    offsets = col_start + tl.arange(0, BLOCK)\n    h_off = pid_b * stride_h_batch + offsets\n    h_vec = tl.load(h_ptr + h_off, mask=offsets < H, other=0.0)\n\n    out = tl.zeros([tl.minimum(BLOCK,H)], dtype=tl.float32)\n          ^\nOutput shape: torch.Size([3, 8])\ntensor([[-0.5683,  0.1345, -0.0171, -0.3386, -0.0296, -0.4176, -0.3993, -0.5165],\n        [ 0.0424,  0.6295,  0.0824,  0.4168,  0.2316, -0.2817, -0.3732, -0.5705],\n        [ 0.2782, -1.2787, -0.3717,  0.1028, -0.6382,  0.7925, -0.0276,  1.1245]],\n       device='cuda:0', grad_fn=<IndexBackward0>)\nMax absolute difference: 0.000000\nMean absolute difference: 0.000000\n✅ Triton output matches PyTorch output closely!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# -------------------------------\n# Consistency check: Triton vs PyTorch\n# -------------------------------\nif USE_TRITON:\n    # PyTorch grouped output\n    out_pt = adaptive_forward_grouped(model, x, depths)\n\n    # Triton output\n    out_triton = adaptive_forward(model, x, depths, W1, b1, W2, b2)\n\n    # Compare\n    max_diff = (out_pt - out_triton).abs().max().item()\n    mean_diff = (out_pt - out_triton).abs().mean().item()\n    print(f\"Max absolute difference: {max_diff:.6f}\")\n    print(f\"Mean absolute difference: {mean_diff:.6f}\")\n\n    if max_diff < 1e-4:\n        print(\"✅ Triton output matches PyTorch output closely!\")\n    else:\n        print(\"⚠️ Triton output differs significantly from PyTorch output.\")\nelse:\n    print(\"Triton not available, skipping consistency check.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:02:19.071474Z","iopub.execute_input":"2025-09-07T13:02:19.071732Z","iopub.status.idle":"2025-09-07T13:02:19.087596Z","shell.execute_reply.started":"2025-09-07T13:02:19.071704Z","shell.execute_reply":"2025-09-07T13:02:19.086921Z"}},"outputs":[{"name":"stdout","text":"⚠️ Triton kernel failed, falling back to PyTorch: at 14:10:\n                           stride_h_batch, stride_h_hidden,\n                           stride_w_depth, stride_w_row, stride_w_col,\n                           stride_b_depth, stride_b_col,\n                           BLOCK: tl.constexpr):\n    pid_b = tl.program_id(0)\n    pid_col = tl.program_id(1)\n    col_start = pid_col * BLOCK\n    offsets = col_start + tl.arange(0, BLOCK)\n    h_off = pid_b * stride_h_batch + offsets\n    h_vec = tl.load(h_ptr + h_off, mask=offsets < H, other=0.0)\n\n    out = tl.zeros([tl.minimum(BLOCK,H)], dtype=tl.float32)\n          ^\nMax absolute difference: 0.000000\nMean absolute difference: 0.000000\n✅ Triton output matches PyTorch output closely!\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Adaptive Depth Forward with Triton Fallback (Kaggle-ready)\n\n\"\"\"This notebook implements an **adaptive depth forward pass**:\n- Uses Triton fused kernel (phase1 + phase2) if available\n- Falls back to PyTorch grouped implementation if Triton is not available\n- Includes a **numerical consistency check**\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:04:43.137677Z","iopub.execute_input":"2025-09-07T13:04:43.138073Z","iopub.status.idle":"2025-09-07T13:04:43.143848Z","shell.execute_reply.started":"2025-09-07T13:04:43.138044Z","shell.execute_reply":"2025-09-07T13:04:43.143206Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'This notebook implements an **adaptive depth forward pass**:\\n- Uses Triton fused kernel (phase1 + phase2) if available\\n- Falls back to PyTorch grouped implementation if Triton is not available\\n- Includes a **numerical consistency check**'"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# Check if Triton is available\nUSE_TRITON = False\ntry:\n    import triton\n    import triton.language as tl\n    USE_TRITON = True\n    print(\"✅ Triton available, will use fused kernel.\")\nexcept Exception as e:\n    print(\"⚠️ Triton not available, falling back to PyTorch implementation.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:05:07.660302Z","iopub.execute_input":"2025-09-07T13:05:07.660982Z","iopub.status.idle":"2025-09-07T13:05:07.665415Z","shell.execute_reply.started":"2025-09-07T13:05:07.660934Z","shell.execute_reply":"2025-09-07T13:05:07.664702Z"}},"outputs":[{"name":"stdout","text":"✅ Triton available, will use fused kernel.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"def adaptive_forward_grouped(model, x, depths):\n    device = x.device\n    depths_sorted, perm = depths.sort()\n    x_sorted = x[perm]\n    h = model.encoder(x_sorted)\n    outputs_sorted_h = torch.zeros_like(h)\n    unique_depths, counts = torch.unique_consecutive(depths_sorted, return_counts=True)\n    start = 0\n    for depth_val, cnt in zip(unique_depths.tolist(), counts.tolist()):\n        end = start + cnt\n        h_group = h[start:end]\n        for d in range(depth_val):\n            h_group = model.core_blocks[d](h_group)\n        outputs_sorted_h[start:end] = h_group\n        start = end\n    _, inv_perm = perm.sort()\n    return outputs_sorted_h[inv_perm]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:05:37.906646Z","iopub.execute_input":"2025-09-07T13:05:37.907214Z","iopub.status.idle":"2025-09-07T13:05:37.912132Z","shell.execute_reply.started":"2025-09-07T13:05:37.907189Z","shell.execute_reply":"2025-09-07T13:05:37.911531Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"if USE_TRITON:\n    BLOCK = 32\n\n    @triton.jit\n    def _phase1_w1_matvec_safe(...):\n        # (Triton phase1 kernel code with dynamic reshape as fixed)\n        pass\n\n    @triton.jit\n    def _phase2_w2_matvec_safe(...):\n        # (Triton phase2 kernel code with dynamic reshape as fixed)\n        pass\n\n    def adaptive_forward_triton_safe(h, depths, W1, b1, W2, b2):\n        # (Safe Triton wrapper calling phase1 + phase2)\n        pass\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:05:56.861788Z","iopub.execute_input":"2025-09-07T13:05:56.862079Z","iopub.status.idle":"2025-09-07T13:05:56.867307Z","shell.execute_reply.started":"2025-09-07T13:05:56.862048Z","shell.execute_reply":"2025-09-07T13:05:56.866445Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_36/1915849122.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    def _phase1_w1_matvec_safe(...):\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (1915849122.py, line 5)","output_type":"error"}],"execution_count":28},{"cell_type":"code","source":"# adaptive_field_runtime.py\n# Requires: torch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport math\nimport random\nfrom typing import Tuple, Dict\n\ntorch.manual_seed(0)\nrandom.seed(0)\n\n# -----------------------------\n# Information Field (central)\n# -----------------------------\nclass InformationField(nn.Module):\n    \"\"\"\n    Encodes an input observation into a field vector (potentials).\n    The output is a vector of size `field_dim` that represents\n    the 'attraction' to different resources and memory regions.\n    \"\"\"\n    def __init__(self, input_dim: int, field_dim: int):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, 128),\n            nn.ReLU(),\n            nn.Linear(128, field_dim)\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # x: [B, input_dim] -> field: [B, field_dim]\n        return self.net(x)\n\n\n# -----------------------------\n# Memory Field (slots + potentials)\n# -----------------------------\nclass MemoryField(nn.Module):\n    \"\"\"\n    Memory represented as N slots, each with a content vector and a scalar potential.\n    Reads and writes are done via flux: the controller provides a read-field,\n    and flux is computed as (softmax of similarity * potentials).\n    Potentials update to reflect recent accesses (like energy wells).\n    \"\"\"\n    def __init__(self, n_slots: int, slot_dim: int, device=None):\n        super().__init__()\n        self.n_slots = n_slots\n        self.slot_dim = slot_dim\n        self.device = device\n        # content initialized randomly; potentials start small\n        self.register_buffer('content', torch.randn(n_slots, slot_dim) * 0.1)\n        self.register_buffer('potentials', torch.zeros(n_slots))  # scalar potential per slot\n\n    def read(self, query: torch.Tensor, temperature: float = 1.0) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Query: [slot_dim] or [B, slot_dim]\n        Returns: read_vec [slot_dim] or [B, slot_dim], and attention weights\n        \"\"\"\n        # compute similarity (cosine) between query and content\n        if query.dim() == 1:\n            q = query.unsqueeze(0)  # [1, D]\n            single = True\n        else:\n            q = query  # [B, D]\n            single = False\n        sim = F.normalize(q, dim=-1) @ F.normalize(self.content, dim=-1).T  # [B, n_slots]\n        # incorporate potentials as additive bias (higher potential -> more attraction)\n        pot = self.potentials.unsqueeze(0).expand(sim.shape)  # [B, n_slots]\n        logits = (sim + pot) / max(1e-6, temperature)\n        attn = F.softmax(logits, dim=-1)  # flux distribution\n        read_vec = attn @ self.content  # [B, D]\n        if single:\n            return read_vec.squeeze(0), attn.squeeze(0)\n        return read_vec, attn\n\n    def write(self, write_vec: torch.Tensor, attn: torch.Tensor, lr: float = 0.1, decay: float = 0.01):\n        \"\"\"\n        write_vec: [D] or [B, D]; attn: corresponding attention weights [n_slots] or [B, n_slots]\n        We update memory content via attention-weighted additive write, and adjust potentials.\n        \"\"\"\n        if write_vec.dim() == 1:\n            w = write_vec.unsqueeze(0)  # [1, D]\n            a = attn.unsqueeze(0)       # [1, n_slots]\n            single = True\n        else:\n            w = write_vec\n            a = attn\n            single = False\n        # attention-weighted update\n        delta = a.T @ w  # [n_slots, D]\n        # normalize by sum of attention per slot (handles batched writes)\n        self.content = (1 - lr) * self.content + lr * delta\n        # potentials increase where attention was focused\n        pot_delta = a.sum(dim=0) if not single else a.squeeze(0)\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n\n    def allocate_new_slot(self, vec: torch.Tensor, pot: float = 1.0):\n        \"\"\"\n        Simple allocation: replace the slot with minimum potential (evict).\n        \"\"\"\n        idx = int(torch.argmin(self.potentials).item())\n        self.content[idx] = vec.detach()\n        self.potentials[idx] = pot\n\n\n# -----------------------------\n# Resource Simulator\n# -----------------------------\nclass ResourceSim:\n    \"\"\"\n    Simulate a compute resource (CPU/GPU/NPU) with different speed and energy cost.\n    The 'run' method executes a small module (nn.Module) on a copy of input and returns latency/cost estimate.\n    \"\"\"\n    def __init__(self, name: str, speed: float, energy_cost: float):\n        \"\"\"\n        speed: multiplier for compute (higher is faster)\n        energy_cost: per-unit cost\n        \"\"\"\n        self.name = name\n        self.speed = speed\n        self.energy_cost = energy_cost\n\n    def run(self, module: nn.Module, x: torch.Tensor) -> Tuple[torch.Tensor, float]:\n        \"\"\"\n        Execute module on x. Return output and simulated latency cost.\n        latency ~ C / speed where C ~ (#elements * flops factor)\n        For prototype we just use a simple heuristic.\n        \"\"\"\n        with torch.no_grad():\n            out = module(x)\n        # heuristics for cost: flops ~ elements * 2\n        flops = x.numel() * 2.0\n        latency = flops / (1e6 * self.speed)  # seconds-ish in simulation\n        energy = latency * self.energy_cost\n        # return also small noise to emulate system variance\n        latency *= (1.0 + 0.05 * (random.random() - 0.5))\n        return out, latency + energy * 0.0  # return latency only for scheduling metric\n\n\n# -----------------------------\n# Controller & Adaptive Runtime\n# -----------------------------\nclass RoutingController(nn.Module):\n    \"\"\"\n    Given the information field vector, produce routing probabilities over resources,\n    and a read/write query for memory.\n    \"\"\"\n    def __init__(self, field_dim: int, n_resources: int, mem_dim: int):\n        super().__init__()\n        self.field2route = nn.Linear(field_dim, n_resources)\n        self.field2query = nn.Linear(field_dim, mem_dim)\n\n    def forward(self, field_vec: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        field_vec: [B, field_dim]\n        returns:\n            route_prob: [B, n_resources] (softmax)\n            mem_query: [B, mem_dim]\n        \"\"\"\n        logits = self.field2route(field_vec)\n        route_prob = F.softmax(logits, dim=-1)\n        query = self.field2query(field_vec)\n        return route_prob, query\n\n\nclass AdaptiveRuntime:\n    \"\"\"\n    Orchestrates: encodes inputs into info-field, controller decides routes and memory queries,\n    memory read happens via flux, resource sims execute submodules, and writes update memory.\n    \"\"\"\n    def __init__(self, input_dim: int, field_dim: int, mem_slots: int, mem_dim: int):\n        self.field = InformationField(input_dim, field_dim)\n        self.controller = RoutingController(field_dim, n_resources=3, mem_dim=mem_dim)\n        # resources: CPU (slow), GPU (fast), NPU (specialized fast+low-energy)\n        self.resources = [\n            ResourceSim(\"CPU\", speed=0.5, energy_cost=1.0),\n            ResourceSim(\"GPU\", speed=4.0, energy_cost=3.0),\n            ResourceSim(\"NPU\", speed=2.5, energy_cost=0.5)\n        ]\n        self.memory = MemoryField(mem_slots, mem_dim)\n        # small compute modules for each resource (for prototype they are different tiny nets)\n        self.modules = [\n            nn.Sequential(nn.Linear(input_dim + mem_dim, 64), nn.ReLU(), nn.Linear(64, mem_dim)),\n            nn.Sequential(nn.Linear(input_dim + mem_dim, 128), nn.ReLU(), nn.Linear(128, mem_dim)),\n            nn.Sequential(nn.Linear(input_dim + mem_dim, 32), nn.ReLU(), nn.Linear(32, mem_dim)),\n        ]\n        # move modules parameters to CPU for now (we simulate device via ResourceSim)\n        for m in self.modules:\n            for p in m.parameters():\n                p.data = p.data  # placeholder; no device movement in simulation\n\n    def step(self, x: torch.Tensor) -> Dict:\n        \"\"\"\n        Single-step processing of a batch x: [B, input_dim]\n        Returns a log with outputs, routing decisions, memory access info, and simulated latency sums.\n        \"\"\"\n        B = x.shape[0]\n        # compute information field\n        field_vec = self.field(x)  # [B, field_dim]\n        # controller: routing probs and memory query\n        route_prob, mem_query = self.controller(field_vec)  # [B, 3], [B, mem_dim]\n\n        outputs = []\n        latencies = []\n        mem_reads = []\n        mem_writes = []\n\n        for i in range(B):\n            rp = route_prob[i]  # [3]\n            # pick resource by sampling (could be argmax or stochastic)\n            idx = int(torch.multinomial(rp, num_samples=1).item())\n            resource = self.resources[idx]\n            module = self.modules[idx]\n\n            # Memory read via flux (attention) using mem_query[i]\n            q = mem_query[i]\n            read_vec, attn = self.memory.read(q, temperature=0.5)  # read: [mem_dim], [n_slots]\n            mem_reads.append(attn)\n\n            # Prepare module input as concat(x, read_vec)\n            inp = torch.cat([x[i], read_vec], dim=-1).unsqueeze(0)  # [1, input+mem_dim]\n\n            # Run on simulated resource (returns out_vec and latency)\n            out_vec, latency = resource.run(module, inp)  # out_vec: [1, mem_dim]\n            out_vec = out_vec.squeeze(0)\n            outputs.append(out_vec)\n            latencies.append(latency)\n\n            # After processing, write new info back to memory (flux: use attn as write weights)\n            write_vec = out_vec.detach()\n            self.memory.write(write_vec, attn, lr=0.05, decay=0.01)\n            mem_writes.append(attn)\n\n            # optionally allocate new slot if max potential exceeds threshold (simple heuristic)\n            if float(torch.max(self.memory.potentials)) > 2.0:\n                # evict lowest potential and insert\n                self.memory.allocate_new_slot(write_vec, pot=1.0)\n\n        outputs = torch.stack(outputs, dim=0)\n        total_latency = sum(latencies)\n        # Logging\n        log = {\n            \"outputs\": outputs,                 # [B, mem_dim]\n            \"route_prob\": route_prob.detach(),  # [B, 3]\n            \"chosen_resources\": [int(torch.multinomial(route_prob[i], 1).item()) for i in range(B)],\n            \"latencies\": latencies,\n            \"total_latency\": total_latency,\n            \"mem_potentials\": self.memory.potentials.detach().clone(),\n            \"mem_reads\": mem_reads,\n            \"mem_writes\": mem_writes,\n        }\n        return log\n\n\n# -----------------------------\n# Demo / test\n# -----------------------------\ndef demo():\n    input_dim = 16\n    field_dim = 12\n    mem_slots = 8\n    mem_dim = 10\n    B = 4\n\n    runtime = AdaptiveRuntime(input_dim=input_dim, field_dim=field_dim, mem_slots=mem_slots, mem_dim=mem_dim)\n\n    # Fake batch of observations with varying 'complexity' (we'll encode complexity in input magnitude)\n    xs = []\n    for i in range(B):\n        complexity = float(i) / (B - 1)  # 0..1\n        vec = torch.randn(input_dim) * (0.5 + complexity * 2.0)  # larger -> \"more complex\"\n        xs.append(vec)\n    x_batch = torch.stack(xs, dim=0)\n\n    print(\"=== Running Adaptive Runtime Demo ===\")\n    # run a few steps, showing how potentials and routing evolve\n    for step in range(6):\n        log = runtime.step(x_batch)\n        print(f\"\\nStep {step}:\")\n        print(\" Route probs (per example):\")\n        print(log[\"route_prob\"].numpy())\n        print(\" Chosen resources (sampled):\", log[\"chosen_resources\"])\n        print(\" Total latency (sim):\", log[\"total_latency\"])\n        print(\" Memory potentials:\", log[\"mem_potentials\"].numpy())\n        # show top attended slot per example\n        top_reads = [int(torch.argmax(r).item()) for r in log[\"mem_reads\"]]\n        print(\" Top read slots:\", top_reads)\n\n    print(\"\\n=== Demo finished ===\")\n\nif __name__ == \"__main__\":\n    demo()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T13:57:40.176045Z","iopub.execute_input":"2025-09-07T13:57:40.176290Z","iopub.status.idle":"2025-09-07T13:57:44.453098Z","shell.execute_reply.started":"2025-09-07T13:57:40.176271Z","shell.execute_reply":"2025-09-07T13:57:44.452369Z"}},"outputs":[{"name":"stdout","text":"=== Running Adaptive Runtime Demo ===\n\nStep 0:\n Route probs (per example):\n[[0.2936131  0.34607193 0.360315  ]\n [0.32896322 0.2888305  0.38220626]\n [0.3929164  0.32743278 0.2796508 ]\n [0.37494013 0.28600407 0.33905584]]\n Chosen resources (sampled): [1, 1, 0, 1]\n Total latency (sim): 0.00015245630893768615\n Memory potentials: [0.00901159 0.00507157 0.00523657 0.00264374 0.00659737 0.00305798\n 0.00393613 0.00384904]\n Top read slots: [4, 0, 1, 0]\n\nStep 1:\n Route probs (per example):\n[[0.2936131  0.34607193 0.360315  ]\n [0.32896322 0.2888305  0.38220626]\n [0.3929164  0.32743278 0.2796508 ]\n [0.37494013 0.28600407 0.33905584]]\n Chosen resources (sampled): [2, 1, 1, 2]\n Total latency (sim): 0.00014991162815804914\n Memory potentials: [0.0174233  0.00998814 0.01029558 0.00522752 0.01291684 0.00605933\n 0.00775349 0.00759111]\n Top read slots: [6, 0, 1, 0]\n\nStep 2:\n Route probs (per example):\n[[0.2936131  0.34607193 0.360315  ]\n [0.32896322 0.2888305  0.38220626]\n [0.3929164  0.32743278 0.2796508 ]\n [0.37494013 0.28600407 0.33905584]]\n Chosen resources (sampled): [2, 1, 2, 2]\n Total latency (sim): 0.0001433286313714722\n Memory potentials: [0.02503301 0.0148542  0.01520918 0.00781711 0.01888474 0.00905818\n 0.01143869 0.01132001]\n Top read slots: [6, 0, 1, 0]\n\nStep 3:\n Route probs (per example):\n[[0.2936131  0.34607193 0.360315  ]\n [0.32896322 0.2888305  0.38220626]\n [0.3929164  0.32743278 0.2796508 ]\n [0.37494013 0.28600407 0.33905584]]\n Chosen resources (sampled): [1, 0, 1, 0]\n Total latency (sim): 7.538786132274261e-05\n Memory potentials: [0.03214008 0.01956805 0.01991737 0.01038829 0.02457539 0.01203029\n 0.01497222 0.01495053]\n Top read slots: [6, 0, 1, 0]\n\nStep 4:\n Route probs (per example):\n[[0.2936131  0.34607193 0.360315  ]\n [0.32896322 0.2888305  0.38220626]\n [0.3929164  0.32743278 0.2796508 ]\n [0.37494013 0.28600407 0.33905584]]\n Chosen resources (sampled): [2, 0, 0, 1]\n Total latency (sim): 0.0001541967133336301\n Memory potentials: [0.03908571 0.0240498  0.02444144 0.01284001 0.03007833 0.01486809\n 0.01830181 0.01842787]\n Top read slots: [6, 0, 1, 0]\n\nStep 5:\n Route probs (per example):\n[[0.2936131  0.34607193 0.360315  ]\n [0.32896322 0.2888305  0.38220626]\n [0.3929164  0.32743278 0.2796508 ]\n [0.37494013 0.28600407 0.33905584]]\n Chosen resources (sampled): [2, 0, 0, 0]\n Total latency (sim): 7.612175604692687e-05\n Memory potentials: [0.0459589  0.02819136 0.02874504 0.015177   0.03542771 0.01759625\n 0.02152122 0.02170439]\n Top read slots: [6, 0, 0, 0]\n\n=== Demo finished ===\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport random\n\n# ------------------------------\n# 1. Simple MNIST Model\n# ------------------------------\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n        self.fc1 = nn.Linear(4608, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.adaptive_avg_pool2d(x, (12, 12))\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)\n\n# ------------------------------\n# 2. Field-Line Runtime Scheduler\n# ------------------------------\nclass FieldRuntime:\n    def __init__(self, resources=[\"cpu\", \"cuda\", \"npu\"], n_slots=8):\n        self.resources = resources\n        self.n_slots = n_slots\n        self.potentials = torch.zeros(n_slots)  # memory potentials\n        self.latencies = {r: 1.0 for r in resources}  # base latency (impedance)\n\n    def route(self, batch_idx):\n        \"\"\"Decide which resource to send this batch (field-line routing).\"\"\"\n        # Field gradient = latency + memory potential cost\n        field_costs = []\n        for r in self.resources:\n            mem_cost = self.potentials.mean().item()  # simplistic global pressure\n            field_costs.append(self.latencies[r] + mem_cost)\n        chosen = int(torch.argmin(torch.tensor(field_costs)))  # follow lowest impedance\n        return self.resources[chosen]\n\n    def update(self, resource):\n        \"\"\"Update field after flux passes.\"\"\"\n        # Increase impedance if resource is used (like saturating resistance)\n        self.latencies[resource] *= 1.05\n        # Update potentials (more flux -> higher)\n        self.potentials += torch.rand(self.n_slots) * 0.01\n        self.potentials *= 0.95  # decay\n\n# ------------------------------\n# 3. Training Loop with Field Runtime\n# ------------------------------\ndef train_field_mnist():\n    # Data\n    transform = transforms.Compose([transforms.ToTensor()])\n    train_data = datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n    train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n\n    # Model\n    model = SimpleCNN()\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # Runtime\n    runtime = FieldRuntime(resources=[\"cpu\", \"cuda\"], n_slots=8)\n\n    # Train few steps demo\n    for step, (x, y) in enumerate(train_loader):\n        if step > 10:  # short demo\n            break\n\n        # Route batch as a \"field line\"\n        device = runtime.route(step)\n        device = torch.device(device if torch.cuda.is_available() or device == \"cpu\" else \"cpu\")\n\n        x, y = x.to(device), y.to(device)\n        model = model.to(device)\n\n        # Forward\n        optimizer.zero_grad()\n        out = model(x)\n        loss = loss_fn(out, y)\n        loss.backward()\n        optimizer.step()\n\n        runtime.update(device.type)\n\n        print(f\"Step {step}: Routed to {device.type}, Loss={loss.item():.4f}, Potentials={runtime.potentials[:3]}\")\n\ntrain_field_mnist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:08:57.151868Z","iopub.execute_input":"2025-09-07T14:08:57.152574Z","iopub.status.idle":"2025-09-07T14:09:04.684289Z","shell.execute_reply.started":"2025-09-07T14:08:57.152533Z","shell.execute_reply":"2025-09-07T14:09:04.683209Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 35.5MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 1.05MB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 9.56MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 7.58MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Step 0: Routed to cpu, Loss=2.3162, Potentials=tensor([0.0041, 0.0008, 0.0083])\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3358034797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Step {step}: Routed to {device.type}, Loss={loss.item():.4f}, Potentials={runtime.potentials[:3]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0mtrain_field_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3358034797.py\u001b[0m in \u001b[0;36mtrain_field_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                             )\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    242\u001b[0m             )\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    245\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    877\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0;31m# Use device beta1 if beta1 is a tensor to ensure all\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0;31m# tensors are on the same device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_lerp_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdevice_beta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_foreach_mul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_exp_avg_sqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# mnist_field_runtime.py\n# Paste into a notebook cell and run. Requires: torch, torchvision\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport random, math\n\ntorch.manual_seed(0)\nrandom.seed(0)\n\n# ------------------------\n# MemoryField: slots + potentials (batched read/write)\n# ------------------------\nclass MemoryField:\n    def __init__(self, n_slots: int, slot_dim: int, device='cpu'):\n        self.n_slots = n_slots\n        self.slot_dim = slot_dim\n        self.device = torch.device(device)\n        # content: [n_slots, slot_dim]\n        self.content = torch.randn(n_slots, slot_dim, device=self.device) * 0.01\n        # scalar potential per slot\n        self.potentials = torch.zeros(n_slots, device=self.device)\n\n    def read(self, queries: torch.Tensor, temperature: float = 0.7):\n        \"\"\"\n        queries: [B, slot_dim]\n        returns:\n            read_vecs: [B, slot_dim]\n            attn: [B, n_slots] attention weights\n        \"\"\"\n        # normalize for cosine similarity\n        q_norm = F.normalize(queries, dim=-1)                # [B, D]\n        c_norm = F.normalize(self.content, dim=-1)          # [n_slots, D]\n        sim = q_norm @ c_norm.T                              # [B, n_slots]\n        # incorporate potentials as bias (higher potential -> more attractive)\n        pot = self.potentials.unsqueeze(0).expand_as(sim)   # [B, n_slots]\n        logits = (sim + pot) / max(1e-6, temperature)\n        attn = F.softmax(logits, dim=-1)                    # [B, n_slots]\n        read_vecs = attn @ self.content                     # [B, D]\n        return read_vecs, attn\n\n    def write(self, write_vecs: torch.Tensor, attn: torch.Tensor, lr: float = 0.08, decay: float = 0.02):\n        \"\"\"\n        write_vecs: [B, D]\n        attn: [B, n_slots]\n        Updates memory content and potentials with batched write using attention weights.\n        \"\"\"\n        # delta per slot: sum_b (attn[b, s] * write_vecs[b])\n        # compute delta: [n_slots, D]\n        delta = attn.T @ write_vecs   # [n_slots, D]\n        # update content with a simple exponential moving average\n        self.content = (1 - lr) * self.content + lr * delta\n        # update potentials: aggregate attention across batch\n        pot_delta = attn.sum(dim=0)   # [n_slots]\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n\n    def allocate_if_needed(self, threshold: float = 2.0, replace_vec=None, pot: float = 1.0):\n        \"\"\"\n        Evict lowest-potential slot if any potential exceeds threshold. Optionally insert replace_vec.\n        \"\"\"\n        if float(self.potentials.max()) > threshold and (replace_vec is not None):\n            idx = int(torch.argmin(self.potentials).item())\n            self.content[idx] = replace_vec.detach().to(self.content.device)\n            self.potentials[idx] = pot\n\n    def to(self, device):\n        self.device = torch.device(device)\n        self.content = self.content.to(self.device)\n        self.potentials = self.potentials.to(self.device)\n\n\n# ------------------------\n# Simple MNIST model that accepts memory read vector\n# ------------------------\nclass CNNWithMemory(nn.Module):\n    def __init__(self, mem_dim: int):\n        super().__init__()\n        # base convs\n        self.conv1 = nn.Conv2d(1, 16, 3, 1)   # -> (16, 26, 26)\n        self.conv2 = nn.Conv2d(16, 32, 3, 1)  # -> (32, 24, 24)\n        # we'll adaptive pool to a small spatial size, then flatten\n        self.pool = nn.AdaptiveAvgPool2d((6,6))  # flatten dimension: 32*6*6 = 1152\n        flat_dim = 32 * 6 * 6\n        self.mem_dim = mem_dim\n        # combine flattened features + memory read vector\n        self.fc1 = nn.Linear(flat_dim + mem_dim, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n        # small 'info encoder' to produce memory query from intermediate features\n        self.info_proj = nn.Sequential(nn.Linear(flat_dim, 64), nn.ReLU(), nn.Linear(64, mem_dim))\n\n    def forward_features(self, x):\n        # returns flattened features used for memory query and for classifier\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        flat = torch.flatten(x, 1)  # [B, flat_dim]\n        return flat\n\n    def forward(self, x, read_vec):\n        \"\"\"\n        x: input images [B, 1, 28, 28]\n        read_vec: [B, mem_dim]\n        \"\"\"\n        flat = self.forward_features(x)               # [B, flat_dim]\n        # combine features and read vector\n        combined = torch.cat([flat, read_vec], dim=-1)\n        h = F.relu(self.fc1(combined))\n        logits = self.fc2(h)\n        return logits, flat\n\n\n# ------------------------\n# FieldRuntime: routing + memory + simulated resources\n# ------------------------\nclass FieldRuntime:\n    def __init__(self, mem_slots=8, mem_dim=32, resources=None, device_hint='cuda' if torch.cuda.is_available() else 'cpu'):\n        if resources is None:\n            # names only; we simulate device constraints\n            resources = ['cpu', 'gpu', 'npu']\n        self.resources = resources\n        # simple per-resource base impedance (lower is faster)\n        self.base_impedance = {'cpu': 1.0, 'gpu': 0.3, 'npu': 0.5}\n        self.load = {r: 0.0 for r in resources}   # simulated dynamic load (increases with assignment)\n        self.mem = MemoryField(n_slots=mem_slots, slot_dim=mem_dim, device=device_hint)\n        self.device_hint = device_hint\n\n    def decide_resource(self, info_vecs: torch.Tensor, temperature: float = 0.5):\n        \"\"\"\n        Decide a resource per example, using info vectors and memory potentials.\n        Strategy:\n            - compute an attraction score to each resource: base_impedance + load penalty - info_strength\n            - info_strength: projection from info_vecs mean magnitude (more complex -> prefer faster resource)\n        Returns:\n            chosen list of resource names length B\n        \"\"\"\n        B = info_vecs.shape[0]\n        # info_strength per example (use L2 norm of info vector)\n        info_strength = info_vecs.norm(dim=-1)  # [B]\n        chosen = []\n        for i in range(B):\n            scores = []\n            for r in self.resources:\n                # lower score -> better (like impedance)\n                score = self.base_impedance[r] + self.load[r] - 0.01 * float(info_strength[i].item())\n                # also consider global memory pressure (mean potential) to slightly bias choices\n                mem_pressure = float(self.mem.potentials.mean().item())\n                score += 0.1 * mem_pressure\n                scores.append(score)\n            idx = int(min(range(len(scores)), key=lambda k: scores[k]))  # argmin\n            chosen.append(self.resources[idx])\n            # increase load a bit on tentative assignment (soft)\n            self.load[self.resources[idx]] += 0.01\n        return chosen\n\n    def step_post_update(self, chosen_resources):\n        \"\"\"\n        Decay loads and potentials a bit to simulate time passing.\n        \"\"\"\n        for r in self.resources:\n            self.load[r] *= 0.95\n        self.mem.potentials *= 0.995\n\n    def to(self, device):\n        self.mem.to(device)\n\n\n# ------------------------\n# Training demo that uses memory as field/flux\n# ------------------------\ndef train_demo(epochs=1, steps_per_epoch=200, batch_size=64, demo_steps=50):\n    device_default = 'cuda' if torch.cuda.is_available() else 'cpu'\n    print(\"Device default:\", device_default)\n\n    # dataset (small subset for demo)\n    transform = transforms.Compose([transforms.ToTensor()])\n    train_ds = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n    loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n\n    # runtime + model\n    mem_slots = 12\n    mem_dim = 32\n    runtime = FieldRuntime(mem_slots=mem_slots, mem_dim=mem_dim, device_hint=device_default)\n    model = CNNWithMemory(mem_dim=mem_dim)\n\n    # optimizer and loss\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n\n    # move model / memory to same base device\n    model.to(device_default)\n    runtime.to(device_default)\n\n    it = iter(loader)\n    for step in range(demo_steps):\n        imgs, labels = next(it)\n        B = imgs.shape[0]\n\n        # 1) compute features on CPU (cheap) to form info queries (we can compute on default device)\n        #    We'll do a feature forward on the model's conv part on CPU first to form queries,\n        #    then decide routing and move necessary tensors.\n        imgs_cpu = imgs.to('cpu')\n        with torch.no_grad():\n            # compute flat features on CPU for information query\n            # temporarily move model convs to cpu if needed\n            model_cpu = model.to('cpu')\n            flat_feats = model_cpu.forward_features(imgs_cpu)  # [B, flat_dim]\n            # project to memory query vector\n            mem_query = model_cpu.info_proj(flat_feats)        # [B, mem_dim]\n            # restore model to default device\n            model.to(device_default)\n\n        # 2) decide resource per example using info queries\n        chosen_resources = runtime.decide_resource(mem_query.to(runtime.mem.device))\n        # For simplicity, we will run the whole batch on the most common chosen resource\n        # (a true implementation could split the batch across devices)\n        # pick the resource with most picks\n        from collections import Counter\n        mode_resource = Counter(chosen_resources).most_common(1)[0][0]\n        # map \"gpu\" -> cuda if available\n        target_device = 'cuda' if (mode_resource == 'gpu' and torch.cuda.is_available()) else 'cpu'\n\n        # 3) Read memory using queries (must be on runtime.mem.device)\n        runtime.mem.to(runtime.mem.device)  # ensure device consistency\n        queries = mem_query.to(runtime.mem.device)            # [B, mem_dim]\n        read_vecs, attn = runtime.mem.read(queries, temperature=0.6)  # [B, mem_dim], [B, n_slots]\n\n        # 4) Move data & model to chosen target device and do forward/backward\n        imgs_dev = imgs.to(target_device)\n        labels_dev = labels.to(target_device)\n        model.to(target_device)\n        model.train()\n        opt.zero_grad()\n        # ensure read_vecs on same device\n        read_dev = read_vecs.to(target_device)\n        logits, flat_post = model(imgs_dev, read_dev)\n        loss = loss_fn(logits, labels_dev)\n        loss.backward()\n        opt.step()\n\n        # 5) After module executes, write flux back to memory:\n        #    create a write vector per example (use detached representation from model)\n        write_vecs = flat_post.detach().to(runtime.mem.device)   # [B, flat_dim] -> need to project to mem_dim\n        # project write_vecs down to mem_dim (simple linear)\n        # make a small projection on the fly (not trained here) - use random projection\n        with torch.no_grad():\n            # random projection matrix stable across steps\n            if not hasattr(train_demo, \"proj\"):\n                torch.manual_seed(1)\n                train_demo.proj = torch.randn(write_vecs.shape[-1], mem_dim, device=runtime.mem.device) * 0.01\n            proj = train_demo.proj\n            write_projected = write_vecs @ proj  # [B, mem_dim]\n\n        runtime.mem.write(write_projected, attn.to(runtime.mem.device), lr=0.06, decay=0.01)\n        runtime.mem.allocate_if_needed(threshold=2.0, replace_vec=write_projected[0], pot=1.0)\n\n        # bookkeeping: decay loads/potentials slightly\n        runtime.step_post_update(chosen_resources)\n\n        # prints for demo insight\n        top_slot = torch.argmax(attn, dim=-1).cpu().numpy().tolist()\n        print(f\"Step {step:03d} | Routed(mode)={mode_resource:4s} -> device={target_device:4s} | Loss={loss.item():.4f} | TopSlots={top_slot} | PotMax={float(runtime.mem.potentials.max()):.4f}\")\n\n    print(\"Demo finished.\")\n\n# Run a short demo:\nif __name__ == \"__main__\":\n    train_demo(demo_steps=40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:10:18.776164Z","iopub.execute_input":"2025-09-07T14:10:18.776433Z","iopub.status.idle":"2025-09-07T14:10:20.400196Z","shell.execute_reply.started":"2025-09-07T14:10:18.776414Z","shell.execute_reply":"2025-09-07T14:10:20.399558Z"}},"outputs":[{"name":"stdout","text":"Device default: cuda\nStep 000 | Routed(mode)=gpu  -> device=cuda | Loss=2.3045 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.0797\nStep 001 | Routed(mode)=gpu  -> device=cuda | Loss=2.2995 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.1488\nStep 002 | Routed(mode)=gpu  -> device=cuda | Loss=2.2943 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.2116\nStep 003 | Routed(mode)=gpu  -> device=cuda | Loss=2.2781 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.2717\nStep 004 | Routed(mode)=gpu  -> device=cuda | Loss=2.2969 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.3303\nStep 005 | Routed(mode)=gpu  -> device=cuda | Loss=2.2760 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.3881\nStep 006 | Routed(mode)=gpu  -> device=cuda | Loss=2.2765 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.4451\nStep 007 | Routed(mode)=gpu  -> device=cuda | Loss=2.2718 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.5018\nStep 008 | Routed(mode)=gpu  -> device=cuda | Loss=2.2606 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.5581\nStep 009 | Routed(mode)=gpu  -> device=cuda | Loss=2.2401 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.6143\nStep 010 | Routed(mode)=gpu  -> device=cuda | Loss=2.2244 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.6704\nStep 011 | Routed(mode)=gpu  -> device=cuda | Loss=2.1995 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.7266\nStep 012 | Routed(mode)=gpu  -> device=cuda | Loss=2.2046 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.7830\nStep 013 | Routed(mode)=gpu  -> device=cuda | Loss=2.1687 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.8397\nStep 014 | Routed(mode)=gpu  -> device=cuda | Loss=2.1583 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.8968\nStep 015 | Routed(mode)=gpu  -> device=cuda | Loss=2.1027 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=0.9544\nStep 016 | Routed(mode)=gpu  -> device=cuda | Loss=2.1086 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.0127\nStep 017 | Routed(mode)=gpu  -> device=cuda | Loss=2.1007 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.0719\nStep 018 | Routed(mode)=gpu  -> device=cuda | Loss=2.0503 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.1321\nStep 019 | Routed(mode)=gpu  -> device=cuda | Loss=1.9690 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.1936\nStep 020 | Routed(mode)=gpu  -> device=cuda | Loss=2.0363 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.2566\nStep 021 | Routed(mode)=gpu  -> device=cuda | Loss=1.8979 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.3215\nStep 022 | Routed(mode)=gpu  -> device=cuda | Loss=1.8849 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.3885\nStep 023 | Routed(mode)=gpu  -> device=cuda | Loss=1.8428 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.4582\nStep 024 | Routed(mode)=gpu  -> device=cuda | Loss=1.8153 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.5309\nStep 025 | Routed(mode)=gpu  -> device=cuda | Loss=1.7059 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.6074\nStep 026 | Routed(mode)=gpu  -> device=cuda | Loss=1.6629 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.6886\nStep 027 | Routed(mode)=gpu  -> device=cuda | Loss=1.6171 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.7752\nStep 028 | Routed(mode)=gpu  -> device=cuda | Loss=1.6427 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.8687\nStep 029 | Routed(mode)=gpu  -> device=cuda | Loss=1.5386 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=1.9706\nStep 030 | Routed(mode)=gpu  -> device=cuda | Loss=1.4808 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=2.0830\nStep 031 | Routed(mode)=gpu  -> device=cuda | Loss=1.3521 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=2.2066\nStep 032 | Routed(mode)=gpu  -> device=cuda | Loss=1.4374 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=2.3446\nStep 033 | Routed(mode)=gpu  -> device=cuda | Loss=1.2463 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=2.5066\nStep 034 | Routed(mode)=gpu  -> device=cuda | Loss=1.1162 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=2.6968\nStep 035 | Routed(mode)=gpu  -> device=cuda | Loss=1.0796 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=2.9258\nStep 036 | Routed(mode)=gpu  -> device=cuda | Loss=1.0651 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=3.2082\nStep 037 | Routed(mode)=gpu  -> device=cuda | Loss=0.9925 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=3.5552\nStep 038 | Routed(mode)=gpu  -> device=cuda | Loss=1.0397 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=3.9757\nStep 039 | Routed(mode)=gpu  -> device=cuda | Loss=0.9718 | TopSlots=[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8] | PotMax=4.4598\nDemo finished.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# mnist_field_memory_trainable.py\n# Train baseline CNN vs CNN+Memory with trainable projections on MNIST\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\ntorch.manual_seed(0)\n\n# ------------------------\n# MemoryField (no params here)\n# ------------------------\nclass MemoryField:\n    def __init__(self, n_slots: int, slot_dim: int, device=\"cpu\"):\n        self.n_slots = n_slots\n        self.slot_dim = slot_dim\n        self.device = torch.device(device)\n        self.content = torch.randn(n_slots, slot_dim, device=self.device) * 0.01\n        self.potentials = torch.zeros(n_slots, device=self.device)\n\n    def read(self, queries: torch.Tensor, temperature: float = 0.7):\n        q_norm = F.normalize(queries, dim=-1)\n        c_norm = F.normalize(self.content, dim=-1)\n        sim = q_norm @ c_norm.T\n        pot = self.potentials.unsqueeze(0).expand_as(sim)\n        logits = (sim + pot) / temperature\n        attn = F.softmax(logits, dim=-1)\n        read_vecs = attn @ self.content\n        return read_vecs, attn\n\n    def write(self, write_vecs: torch.Tensor, attn: torch.Tensor, lr=0.08, decay=0.02):\n        delta = attn.T @ write_vecs\n        self.content = (1 - lr) * self.content + lr * delta\n        pot_delta = attn.sum(dim=0)\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n\n    def reset(self):\n        self.content.zero_()\n        self.potentials.zero_()\n\n    def to(self, device):\n        self.device = torch.device(device)\n        self.content = self.content.to(device)\n        self.potentials = self.potentials.to(device)\n\n\n# ------------------------\n# CNN baseline\n# ------------------------\nclass BaselineCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n        self.pool = nn.AdaptiveAvgPool2d((6, 6))\n        flat_dim = 32 * 6 * 6\n        self.fc1 = nn.Linear(flat_dim, 128)\n        self.fc2 = nn.Linear(128, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        flat = torch.flatten(x, 1)\n        h = F.relu(self.fc1(flat))\n        return self.fc2(h)\n\n\n# ------------------------\n# CNN with Memory\n# ------------------------\nclass CNNWithMemory(nn.Module):\n    def __init__(self, mem_slots=12, mem_dim=32):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 16, 3, 1)\n        self.conv2 = nn.Conv2d(16, 32, 3, 1)\n        self.pool = nn.AdaptiveAvgPool2d((6, 6))\n        self.flat_dim = 32 * 6 * 6\n        self.mem_dim = mem_dim\n        # Projections: trainable\n        self.query_proj = nn.Linear(self.flat_dim, mem_dim)\n        self.write_proj = nn.Linear(self.flat_dim, mem_dim)\n        # Classifier takes flat + memory read\n        self.fc1 = nn.Linear(self.flat_dim + mem_dim, 128)\n        self.fc2 = nn.Linear(128, 10)\n        # External memory\n        self.memory = MemoryField(mem_slots, mem_dim)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        flat = torch.flatten(x, 1)  # [B, flat_dim]\n        # Query memory\n        q = self.query_proj(flat)\n        read_vecs, attn = self.memory.read(q)\n        # Classify\n        combined = torch.cat([flat, read_vecs], dim=-1)\n        h = F.relu(self.fc1(combined))\n        logits = self.fc2(h)\n        # Write back\n        w = self.write_proj(flat).detach()\n        self.memory.write(w, attn)\n        return logits\n\n\n# ------------------------\n# Training utility\n# ------------------------\ndef train_model(model, train_loader, test_loader, device, epochs=1):\n    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n    loss_fn = nn.CrossEntropyLoss()\n    model.to(device)\n    for epoch in range(epochs):\n        model.train()\n        for imgs, labels in train_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            opt.zero_grad()\n            logits = model(imgs)\n            loss = loss_fn(logits, labels)\n            loss.backward()\n            opt.step()\n        acc = evaluate(model, test_loader, device)\n        print(f\"Epoch {epoch+1}: Test accuracy = {acc:.4f}\")\n    return model\n\n\ndef evaluate(model, test_loader, device):\n    model.eval()\n    correct = total = 0\n    with torch.no_grad():\n        for imgs, labels in test_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            out = model(imgs)\n            preds = out.argmax(dim=1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    return correct / total\n\n\n# ------------------------\n# Run experiment\n# ------------------------\ndef run_experiment():\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    transform = transforms.Compose([transforms.ToTensor()])\n    train_ds = datasets.MNIST(root=\".\", train=True, download=True, transform=transform)\n    test_ds = datasets.MNIST(root=\".\", train=False, transform=transform)\n    train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n    test_loader = DataLoader(test_ds, batch_size=512)\n\n    print(\"=== Baseline CNN ===\")\n    baseline = BaselineCNN()\n    train_model(baseline, train_loader, test_loader, device, epochs=2)\n\n    print(\"\\n=== CNN with Memory ===\")\n    with_memory = CNNWithMemory()\n    train_model(with_memory, train_loader, test_loader, device, epochs=2)\n\n\nif __name__ == \"__main__\":\n    run_experiment()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:11:51.781870Z","iopub.execute_input":"2025-09-07T14:11:51.782166Z","iopub.status.idle":"2025-09-07T14:12:08.508839Z","shell.execute_reply.started":"2025-09-07T14:11:51.782143Z","shell.execute_reply":"2025-09-07T14:12:08.507600Z"}},"outputs":[{"name":"stdout","text":"=== Baseline CNN ===\nEpoch 1: Test accuracy = 0.9752\nEpoch 2: Test accuracy = 0.9824\n\n=== CNN with Memory ===\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3852330831.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_36/3852330831.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== CNN with Memory ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0mwith_memory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNWithMemory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_memory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3852330831.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, test_loader, device, epochs)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3852330831.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Query memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mread_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Classify\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_vecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3852330831.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, queries, temperature)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mq_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mc_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_norm\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mc_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mpot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpot\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_mm)","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\n\n# -------------------------------\n# Adaptive MemoryField\n# -------------------------------\nclass MemoryField(nn.Module):\n    def __init__(self, n_slots: int, dim: int):\n        super().__init__()\n        self.n_slots = n_slots\n        self.dim = dim\n        self.register_buffer(\"content\", torch.randn(n_slots, dim) * 0.01)\n        self.register_buffer(\"potentials\", torch.zeros(n_slots))\n\n    def read(self, queries: torch.Tensor, temperature: float = 1.5):\n        q_norm = F.normalize(queries, dim=-1)\n        c_norm = F.normalize(self.content, dim=-1)\n        sim = q_norm @ c_norm.T   # [B, n_slots]\n\n        pot = self.potentials.unsqueeze(0).expand_as(sim)\n        pot = pot - pot.mean(dim=-1, keepdim=True)\n\n        logits = (sim + pot) / temperature\n        attn = F.softmax(logits, dim=-1)\n        read_vecs = attn @ self.content\n        return read_vecs, attn\n\n    def write(self, write_vecs: torch.Tensor, attn: torch.Tensor,\n              lr: float = 0.05, decay: float = 0.05, clamp_max=2.0):\n        delta = attn.T @ write_vecs\n        self.content = (1 - lr) * self.content + lr * delta\n        pot_delta = attn.sum(dim=0)\n\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n        self.potentials = torch.clamp(self.potentials, min=0.0, max=clamp_max)\n\n# -------------------------------\n# Simple MLP with memory\n# -------------------------------\nclass AdaptiveNet(nn.Module):\n    def __init__(self, input_dim=28*28, hidden_dim=128, mem_slots=16, mem_dim=64, num_classes=10):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.memory = MemoryField(mem_slots, mem_dim)\n        self.fc2 = nn.Linear(hidden_dim + mem_dim, num_classes)\n\n    def forward(self, x):\n        h = F.relu(self.fc1(x))\n        read_vecs, attn = self.memory.read(h)\n        combined = torch.cat([h, read_vecs], dim=-1)\n        out = self.fc2(combined)\n        return out, attn, h\n\n# -------------------------------\n# Helpers\n# -------------------------------\ndef attn_entropy(attn: torch.Tensor):\n    return -(attn * (attn + 1e-12).log()).sum(dim=-1).mean()\n\n# -------------------------------\n# Training loop\n# -------------------------------\ndef train_mnist(epochs=1, batch_size=64, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n    transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.view(-1))])\n    trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\n    model = AdaptiveNet().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    for step, (x, y) in enumerate(trainloader):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        out, attn, h = model(x)\n        task_loss = F.cross_entropy(out, y)\n        entropy = attn_entropy(attn)\n        beta = 0.01\n        loss = task_loss - beta * entropy\n\n        loss.backward()\n        optimizer.step()\n\n        model.memory.write(h.detach(), attn.detach())\n\n        if step % 50 == 0:\n            print(\n                f\"Step {step:04d} | \"\n                f\"Loss={task_loss.item():.4f} | \"\n                f\"Entropy={entropy.item():.4f} | \"\n                f\"AttnMaxMean={attn.max(dim=-1).values.mean().item():.3f} | \"\n                f\"PotMean={model.memory.potentials.mean().item():.3f} \"\n                f\"PotMax={model.memory.potentials.max().item():.3f}\"\n            )\n\n        if step > 500:  # shorten demo\n            break\n\n    return model\n\n# -------------------------------\n# Run demo\n# -------------------------------\nif __name__ == \"__main__\":\n    print(\"=== Running Adaptive MNIST Demo ===\")\n    model = train_mnist()\n    print(\"=== Demo finished ===\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:14:33.490261Z","iopub.execute_input":"2025-09-07T14:14:33.490877Z","iopub.status.idle":"2025-09-07T14:14:35.605556Z","shell.execute_reply.started":"2025-09-07T14:14:33.490853Z","shell.execute_reply":"2025-09-07T14:14:35.604554Z"}},"outputs":[{"name":"stdout","text":"=== Running Adaptive MNIST Demo ===\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 37.4MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 991kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 9.67MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 9.11MB/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/2792773678.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Running Adaptive MNIST Demo ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Demo finished ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2792773678.py\u001b[0m in \u001b[0;36mtrain_mnist\u001b[0;34m(epochs, batch_size, device)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mtask_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2792773678.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mread_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_vecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/2792773678.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, queries, temperature)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mq_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mc_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_norm\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mc_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m   \u001b[0;31m# [B, n_slots]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x128 and 64x16)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (64x128 and 64x16)","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# -------------------------------\n# Adaptive MemoryField\n# -------------------------------\nclass MemoryField(nn.Module):\n    def __init__(self, n_slots: int, dim: int):\n        super().__init__()\n        self.n_slots = n_slots\n        self.dim = dim\n        self.register_buffer(\"content\", torch.randn(n_slots, dim) * 0.01)\n        self.register_buffer(\"potentials\", torch.zeros(n_slots))\n\n    def read(self, queries: torch.Tensor, temperature: float = 1.5):\n        q_norm = F.normalize(queries, dim=-1)\n        c_norm = F.normalize(self.content, dim=-1)\n        sim = q_norm @ c_norm.T\n\n        pot = self.potentials.unsqueeze(0).expand_as(sim)\n        pot = pot - pot.mean(dim=-1, keepdim=True)\n\n        logits = (sim + pot) / temperature\n        attn = F.softmax(logits, dim=-1)\n        read_vecs = attn @ self.content\n        return read_vecs, attn\n\n    def write(self, write_vecs: torch.Tensor, attn: torch.Tensor,\n              lr: float = 0.05, decay: float = 0.05, clamp_max=2.0):\n        delta = attn.T @ write_vecs\n        self.content = (1 - lr) * self.content + lr * delta\n        pot_delta = attn.sum(dim=0)\n\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n        self.potentials = torch.clamp(self.potentials, min=0.0, max=clamp_max)\n\n# -------------------------------\n# Simple MLP with memory\n# -------------------------------\nclass AdaptiveNet(nn.Module):\n    def __init__(self, input_dim=28*28, hidden_dim=128, mem_slots=16, mem_dim=64, num_classes=10):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.memory = MemoryField(mem_slots, mem_dim)\n        self.fc2 = nn.Linear(hidden_dim + mem_dim, num_classes)\n\n    def forward(self, x):\n        h = F.relu(self.fc1(x))\n        read_vecs, attn = self.memory.read(h)\n        combined = torch.cat([h, read_vecs], dim=-1)\n        out = self.fc2(combined)\n        return out, attn, h\n\n# -------------------------------\n# Helpers\n# -------------------------------\ndef attn_entropy(attn: torch.Tensor):\n    return -(attn * (attn + 1e-12).log()).sum(dim=-1).mean()\n\ndef plot_memory(attn, potentials, step):\n    plt.clf()\n    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n\n    # Heatmap of attention\n    axs[0].imshow(attn[:32].detach().cpu().numpy(), aspect=\"auto\", cmap=\"viridis\")\n    axs[0].set_title(f\"Step {step} - Attn Heatmap (first 32 examples)\")\n    axs[0].set_xlabel(\"Memory Slots\")\n    axs[0].set_ylabel(\"Examples\")\n\n    # Line plot of potentials\n    axs[1].bar(np.arange(len(potentials)), potentials.detach().cpu().numpy())\n    axs[1].set_title(\"Memory Potentials\")\n    axs[1].set_xlabel(\"Slot\")\n    axs[1].set_ylabel(\"Potential\")\n\n    plt.tight_layout()\n    plt.pause(0.01)  # live update\n\n# -------------------------------\n# Training loop\n# -------------------------------\ndef train_mnist(epochs=1, batch_size=64, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n    transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.view(-1))])\n    trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\n    model = AdaptiveNet().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    plt.ion()  # interactive mode for live plotting\n\n    for step, (x, y) in enumerate(trainloader):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        out, attn, h = model(x)\n        task_loss = F.cross_entropy(out, y)\n        entropy = attn_entropy(attn)\n        beta = 0.01\n        loss = task_loss - beta * entropy\n\n        loss.backward()\n        optimizer.step()\n        model.memory.write(h.detach(), attn.detach())\n\n        if step % 50 == 0:\n            print(\n                f\"Step {step:04d} | \"\n                f\"Loss={task_loss.item():.4f} | \"\n                f\"Entropy={entropy.item():.4f} | \"\n                f\"AttnMaxMean={attn.max(dim=-1).values.mean().item():.3f} | \"\n                f\"PotMean={model.memory.potentials.mean().item():.3f} \"\n                f\"PotMax={model.memory.potentials.max().item():.3f}\"\n            )\n            plot_memory(attn, model.memory.potentials, step)\n\n        if step > 500:  # shorten demo\n            break\n\n    plt.ioff()\n    plt.show()\n\n    return model\n\n# -------------------------------\n# Run demo\n# -------------------------------\nif __name__ == \"__main__\":\n    print(\"=== Running Adaptive MNIST Demo with Visualization ===\")\n    model = train_mnist()\n    print(\"=== Demo finished ===\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:15:24.324933Z","iopub.execute_input":"2025-09-07T14:15:24.325229Z","iopub.status.idle":"2025-09-07T14:15:24.595382Z","shell.execute_reply.started":"2025-09-07T14:15:24.325207Z","shell.execute_reply":"2025-09-07T14:15:24.594299Z"}},"outputs":[{"name":"stdout","text":"=== Running Adaptive MNIST Demo with Visualization ===\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1619415519.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Running Adaptive MNIST Demo with Visualization ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=== Demo finished ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1619415519.py\u001b[0m in \u001b[0;36mtrain_mnist\u001b[0;34m(epochs, batch_size, device)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mtask_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mentropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1619415519.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mread_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread_vecs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/1619415519.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, queries, temperature)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mq_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mc_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_norm\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mc_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mpot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpotentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x128 and 64x16)"],"ename":"RuntimeError","evalue":"mat1 and mat2 shapes cannot be multiplied (64x128 and 64x16)","output_type":"error"}],"execution_count":6},{"cell_type":"code","source":"# ============================================================\n# Adaptive MNIST with MemoryField + Visualization (Single Cell)\n# ============================================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# -------------------------------\n# Adaptive MemoryField\n# -------------------------------\nclass MemoryField(nn.Module):\n    def __init__(self, n_slots: int, dim: int):\n        super().__init__()\n        self.n_slots = n_slots\n        self.dim = dim\n        self.register_buffer(\"content\", torch.randn(n_slots, dim) * 0.01)\n        self.register_buffer(\"potentials\", torch.zeros(n_slots))\n\n    def read(self, queries: torch.Tensor, temperature: float = 1.5):\n        q_norm = F.normalize(queries, dim=-1)\n        c_norm = F.normalize(self.content, dim=-1)\n        sim = q_norm @ c_norm.T   # [B, n_slots]\n\n        pot = self.potentials.unsqueeze(0).expand_as(sim)\n        pot = pot - pot.mean(dim=-1, keepdim=True)\n\n        logits = (sim + pot) / temperature\n        attn = F.softmax(logits, dim=-1)\n        read_vecs = attn @ self.content\n        return read_vecs, attn\n\n    def write(self, write_vecs: torch.Tensor, attn: torch.Tensor,\n              lr: float = 0.05, decay: float = 0.05, clamp_max=2.0):\n        delta = attn.T @ write_vecs\n        self.content = (1 - lr) * self.content + lr * delta\n        pot_delta = attn.sum(dim=0)\n\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n        self.potentials = torch.clamp(self.potentials, min=0.0, max=clamp_max)\n\n# -------------------------------\n# Adaptive Net with query projection\n# -------------------------------\nclass AdaptiveNet(nn.Module):\n    def __init__(self, input_dim=28*28, hidden_dim=128, mem_slots=16, mem_dim=64, num_classes=10):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.query_proj = nn.Linear(hidden_dim, mem_dim)   # projection into memory space\n        self.memory = MemoryField(mem_slots, mem_dim)\n        self.fc2 = nn.Linear(hidden_dim + mem_dim, num_classes)\n\n    def forward(self, x):\n        h = F.relu(self.fc1(x))       # raw hidden\n        q = self.query_proj(h)        # projected query\n        read_vecs, attn = self.memory.read(q)\n        combined = torch.cat([h, read_vecs], dim=-1)\n        out = self.fc2(combined)\n        return out, attn, h, q        # return both h and q\n\n# -------------------------------\n# Helpers\n# -------------------------------\ndef attn_entropy(attn: torch.Tensor):\n    return -(attn * (attn + 1e-12).log()).sum(dim=-1).mean()\n\n# -------------------------------\n# Training + Visualization\n# -------------------------------\ndef train_mnist(epochs=1, batch_size=64, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n    transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.view(-1))])\n    trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\n    model = AdaptiveNet().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    # Tracking\n    attn_history = []\n    pot_history = []\n    h_norms = []\n    q_norms = []\n\n    for step, (x, y) in enumerate(trainloader):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        out, attn, h, q = model(x)\n        task_loss = F.cross_entropy(out, y)\n        entropy = attn_entropy(attn)\n        beta = 0.01\n        loss = task_loss - beta * entropy\n\n        loss.backward()\n        optimizer.step()\n        model.memory.write(q.detach(), attn.detach())\n\n        # Log\n        attn_history.append(attn.mean(0).detach().cpu().numpy())\n        pot_history.append(model.memory.potentials.detach().cpu().numpy())\n        h_norms.append(h.norm(dim=-1).mean().item())\n        q_norms.append(q.norm(dim=-1).mean().item())\n\n        if step % 50 == 0:\n            print(\n                f\"Step {step:04d} | \"\n                f\"Loss={task_loss.item():.4f} | \"\n                f\"Entropy={entropy.item():.4f} | \"\n                f\"PotMean={model.memory.potentials.mean().item():.3f} \"\n                f\"PotMax={model.memory.potentials.max().item():.3f}\"\n            )\n\n        if step > 300:  # shorten demo\n            break\n\n    # Visualization\n    attn_arr = np.stack(attn_history)\n    pot_arr = np.stack(pot_history)\n\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n    im0 = axes[0].imshow(attn_arr.T, aspect=\"auto\", cmap=\"viridis\")\n    axes[0].set_title(\"Attention over slots\")\n    axes[0].set_xlabel(\"Step\")\n    axes[0].set_ylabel(\"Slot\")\n    plt.colorbar(im0, ax=axes[0])\n\n    im1 = axes[1].imshow(pot_arr.T, aspect=\"auto\", cmap=\"plasma\")\n    axes[1].set_title(\"Memory potentials\")\n    axes[1].set_xlabel(\"Step\")\n    plt.colorbar(im1, ax=axes[1])\n\n    axes[2].plot(h_norms, label=\"h (raw hidden)\")\n    axes[2].plot(q_norms, label=\"q (projected)\")\n    axes[2].set_title(\"Norms of h vs q\")\n    axes[2].set_xlabel(\"Step\")\n    axes[2].legend()\n\n    plt.tight_layout()\n    plt.show()\n\n    return model\n\n# -------------------------------\n# Run demo\n# -------------------------------\nif __name__ == \"__main__\":\n    print(\"=== Running Adaptive MNIST Demo with Visualization ===\")\n    model = train_mnist()\n    print(\"=== Demo finished ===\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:53:43.927073Z","iopub.execute_input":"2025-09-07T14:53:43.927751Z","iopub.status.idle":"2025-09-07T14:53:47.889084Z","shell.execute_reply.started":"2025-09-07T14:53:43.927721Z","shell.execute_reply":"2025-09-07T14:53:47.888317Z"}},"outputs":[{"name":"stdout","text":"=== Running Adaptive MNIST Demo with Visualization ===\nStep 0000 | Loss=2.3323 | Entropy=2.7706 | PotMean=0.200 PotMax=0.211\nStep 0050 | Loss=0.6295 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0100 | Loss=0.4116 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0150 | Loss=0.4546 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0200 | Loss=0.5043 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0250 | Loss=0.3436 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0300 | Loss=0.3499 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x400 with 5 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"=== Demo finished ===\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ============================================================\n# Adaptive MNIST with MemoryField + Live Visualization\n# ============================================================\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# -------------------------------\n# Adaptive MemoryField\n# -------------------------------\nclass MemoryField(nn.Module):\n    def __init__(self, n_slots: int, dim: int):\n        super().__init__()\n        self.n_slots = n_slots\n        self.dim = dim\n        self.register_buffer(\"content\", torch.randn(n_slots, dim) * 0.01)\n        self.register_buffer(\"potentials\", torch.zeros(n_slots))\n\n    def read(self, queries: torch.Tensor, temperature: float = 1.5):\n        q_norm = F.normalize(queries, dim=-1)\n        c_norm = F.normalize(self.content, dim=-1)\n        sim = q_norm @ c_norm.T   # [B, n_slots]\n\n        pot = self.potentials.unsqueeze(0).expand_as(sim)\n        pot = pot - pot.mean(dim=-1, keepdim=True)\n\n        logits = (sim + pot) / temperature\n        attn = F.softmax(logits, dim=-1)\n        read_vecs = attn @ self.content\n        return read_vecs, attn\n\n    def write(self, write_vecs: torch.Tensor, attn: torch.Tensor,\n              lr: float = 0.05, decay: float = 0.05, clamp_max=2.0):\n        delta = attn.T @ write_vecs\n        self.content = (1 - lr) * self.content + lr * delta\n        pot_delta = attn.sum(dim=0)\n        self.potentials = (1 - decay) * self.potentials + decay * pot_delta.detach()\n        self.potentials = torch.clamp(self.potentials, min=0.0, max=clamp_max)\n\n# -------------------------------\n# Adaptive Net with query projection\n# -------------------------------\nclass AdaptiveNet(nn.Module):\n    def __init__(self, input_dim=28*28, hidden_dim=128, mem_slots=16, mem_dim=64, num_classes=10):\n        super().__init__()\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.query_proj = nn.Linear(hidden_dim, mem_dim)\n        self.memory = MemoryField(mem_slots, mem_dim)\n        self.fc2 = nn.Linear(hidden_dim + mem_dim, num_classes)\n\n    def forward(self, x):\n        h = F.relu(self.fc1(x))\n        q = self.query_proj(h)\n        read_vecs, attn = self.memory.read(q)\n        combined = torch.cat([h, read_vecs], dim=-1)\n        out = self.fc2(combined)\n        return out, attn, h, q\n\n# -------------------------------\n# Helpers\n# -------------------------------\ndef attn_entropy(attn: torch.Tensor):\n    return -(attn * (attn + 1e-12).log()).sum(dim=-1).mean()\n\n# -------------------------------\n# Training with Live Viz\n# -------------------------------\ndef train_mnist_live(epochs=1, batch_size=64, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n    transform = T.Compose([T.ToTensor(), T.Lambda(lambda x: x.view(-1))])\n    trainset = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n\n    model = AdaptiveNet().to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\n    attn_history = []\n    pot_history = []\n    h_norms = []\n    q_norms = []\n\n    # Setup live plot\n    plt.ion()\n    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n\n    for step, (x, y) in enumerate(trainloader):\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        out, attn, h, q = model(x)\n        task_loss = F.cross_entropy(out, y)\n        entropy = attn_entropy(attn)\n        beta = 0.01\n        loss = task_loss - beta * entropy\n\n        loss.backward()\n        optimizer.step()\n        model.memory.write(q.detach(), attn.detach())\n\n        attn_history.append(attn.mean(0).detach().cpu().numpy())\n        pot_history.append(model.memory.potentials.detach().cpu().numpy())\n        h_norms.append(h.norm(dim=-1).mean().item())\n        q_norms.append(q.norm(dim=-1).mean().item())\n\n        # Print logs\n        if step % 20 == 0:\n            print(\n                f\"Step {step:04d} | \"\n                f\"Loss={task_loss.item():.4f} | \"\n                f\"Entropy={entropy.item():.4f} | \"\n                f\"PotMean={model.memory.potentials.mean().item():.3f} \"\n                f\"PotMax={model.memory.potentials.max().item():.3f}\"\n            )\n\n        # Update live plot\n        if step % 20 == 0:\n            attn_arr = np.stack(attn_history)\n            pot_arr = np.stack(pot_history)\n\n            axes[0].cla()\n            im0 = axes[0].imshow(attn_arr.T, aspect=\"auto\", cmap=\"viridis\")\n            axes[0].set_title(\"Attention over slots\")\n\n            axes[1].cla()\n            im1 = axes[1].imshow(pot_arr.T, aspect=\"auto\", cmap=\"plasma\")\n            axes[1].set_title(\"Memory potentials\")\n\n            axes[2].cla()\n            axes[2].plot(h_norms, label=\"h\")\n            axes[2].plot(q_norms, label=\"q\")\n            axes[2].set_title(\"Norms h vs q\")\n            axes[2].legend()\n\n            plt.pause(0.01)\n\n        if step > 200:  # shorten demo\n            break\n\n    plt.ioff()\n    plt.show()\n    return model\n\n# -------------------------------\n# Run live demo\n# -------------------------------\nif __name__ == \"__main__\":\n    print(\"=== Running Adaptive MNIST with Live Visualization ===\")\n    model = train_mnist_live()\n    print(\"=== Demo finished ===\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T14:54:35.732486Z","iopub.execute_input":"2025-09-07T14:54:35.733205Z","iopub.status.idle":"2025-09-07T14:54:39.012666Z","shell.execute_reply.started":"2025-09-07T14:54:35.733180Z","shell.execute_reply":"2025-09-07T14:54:39.011918Z"}},"outputs":[{"name":"stdout","text":"=== Running Adaptive MNIST with Live Visualization ===\nStep 0000 | Loss=2.2944 | Entropy=2.7689 | PotMean=0.200 PotMax=0.233\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1500x400 with 3 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"Step 0020 | Loss=1.4627 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0040 | Loss=0.6662 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0060 | Loss=0.5674 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0080 | Loss=0.5910 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0100 | Loss=0.4970 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0120 | Loss=0.2321 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0140 | Loss=0.4931 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0160 | Loss=0.1803 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0180 | Loss=0.1890 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\nStep 0200 | Loss=0.2520 | Entropy=2.7726 | PotMean=2.000 PotMax=2.000\n=== Demo finished ===\n","output_type":"stream"}],"execution_count":8}]}