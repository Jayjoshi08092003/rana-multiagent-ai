
# ğŸ¤– RANA: Recursive Adaptive Neural Agent

**RANA** (Recursive Adaptive Neural Agent) is an intelligent multimodal AI system developed to classify and interpret human facial emotions in real time. RANA fuses powerful deep learning architectures with adaptive learning techniques for robust emotion recognition.

---

## ğŸš€ Overview

RANA combines:
- Convolutional Neural Networks (CNNs) like **ResNeXt-50** and **MiniXception**
- A facial emotion dataset (**FER-2013**)
- Real-time webcam integration
- YOLOv5 for efficient face detection
- Custom adaptive learning logic

This allows RANA to perform:
- ğŸ¯ Emotion classification with 7 key emotions
- ğŸ–¼ï¸ Face detection and cropping
- ğŸ” Self-improvement via adaptive learning loops
- ğŸ“¦ Future scalability to multimodal contexts (e.g., text + vision)

---

## ğŸ” Emotion Classes

- Angry ğŸ˜   
- Disgust ğŸ¤¢  
- Fear ğŸ˜¨  
- Happy ğŸ˜„  
- Neutral ğŸ˜  
- Sad ğŸ˜¢  
- Surprise ğŸ˜²  

---

## ğŸ› ï¸ Core Components

### ğŸ“¦ CNN Backbone  
- Initially trained using **ResNeXt-50**
- Deployed in real-time with **MiniXception** for speed and efficiency

### ğŸ¯ Training  
- Dataset: FER-2013 (grayscale, 48x48 images)
- Data Augmentation: Horizontal flips, normalization
- Loss Function: CrossEntropyLoss  
- Optimizer: Adam  

### ğŸ“· Real-Time Detection  
- Face detection via **YOLOv5**
- Emotion prediction from webcam streams
- Deployment-ready via OpenCV

### ğŸ§  Adaptive Learning Loop  
- Dynamically adjusts learning rate based on validation loss
- Tracks best model using checkpointing
- Can be extended for online learning or reinforcement learning

---

## ğŸ“ Repository Structure

\`\`\`
RANA/
â”œâ”€â”€ model.py                  # Model definition (MiniXception/ResNeXt)
â”œâ”€â”€ train_model.py            # Emotion classifier training script
â”œâ”€â”€ realtime_emotion_detect.py # Real-time webcam inference
â”œâ”€â”€ datasets/                 # FER-2013 data (or path to it)
â”œâ”€â”€ best_model.pth            # Trained model checkpoint
â”œâ”€â”€ README.md                 # Project overview (this file)
\`\`\`

---

## ğŸ’¡ Applications

- Human-computer interaction  
- Affective computing  
- Virtual assistants and robots  
- Education technology (edtech) feedback systems  
- Health monitoring tools

---

## ğŸ§© Future Roadmap

- ğŸ§  Integrate text + audio for full multimodal emotional AI  
- ğŸŒ Add multilingual support  
- âš™ï¸ Export as REST API or ONNX for mobile deployment  
- ğŸ“š Fine-tune with real-world emotion datasets

---

## ğŸ“¬ Contact

**ğŸ‘¨â€ğŸ’» Developer:** Jay Joshi  
ğŸ“§ Email: jayjoshi08092003@gmail.com  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/jayjoshi08092003)  
ğŸ”— [GitHub](https://github.com/Jayjoshi08092003)

---

## ğŸ“„ License

Licensed under the [MIT License](LICENSE).

---

## ğŸ·ï¸ Tags

`#RANA` `#AI`  `#EmotionRecognition` `#DeepLearning` `#RealTimeAI` `#FER2013`


