# -*- coding: utf-8 -*-
"""RAMANUJANRANA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KPmukpCMDG3gEJFhAHPi7JQDA3af4F6E
"""

#!/usr/bin/env python3
# rrnn_cifar10_prototype.py
# Requirements: torch, torchvision, tqdm
# Usage: python rrnn_cifar10_prototype.py --epochs 20 --batch-size 128 --max-depth 6

import argparse, random, math, os
import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim
import torchvision, torchvision.transforms as T
from torch.utils.data import DataLoader
from tqdm import tqdm

# ---------- simple architectures (Encoder, RamanujanCoreBlock, Predictor, AdaptiveModel) ----------
class Encoder(nn.Module):
    def __init__(self, in_channels, hidden_dim):
        super().__init__()
        # simple conv encoder for CIFAR-10 -> flattened features
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(128, hidden_dim)
    def forward(self, x):
        h = self.conv(x).view(x.size(0), -1)
        return F.relu(self.fc(h))

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self, h):
        r = F.relu(self.fc1(h))
        r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class Predictor(nn.Module):
    def __init__(self, dim, out_dim):
        super().__init__()
        self.head = nn.Sequential(nn.Linear(dim, dim//2), nn.ReLU(), nn.Linear(dim//2, out_dim))
    def forward(self, h): return self.head(h)

class AdaptiveModel(nn.Module):
    def __init__(self, in_channels, hidden_dim, out_dim, max_depth=6):
        super().__init__()
        self.encoder = Encoder(in_channels, hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = Predictor(hidden_dim, out_dim)
        self.max_depth = max_depth
    def forward(self, x, depth):
        h = self.encoder(x)
        for i in range(depth):
            h = self.core_blocks[i](h)
        return self.predictor(h)

# ---------- Meta-controller (batch-level) ----------
class MetaController(nn.Module):
    def __init__(self, obs_dim, max_depth):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(obs_dim, 128), nn.ReLU(), nn.Linear(128, max_depth))
    def forward(self, obs): return self.net(obs)

# ---------- utility ----------
def accuracy(preds, labels): return (preds.argmax(dim=1) == labels).float().mean().item()

# ---------- training script ----------
def train(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    transform_train = T.Compose([T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    transform_test = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    train_loader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=2)
    test_loader = DataLoader(testset, batch_size=args.batch_size, shuffle=False, num_workers=2)

    model = AdaptiveModel(3, args.hidden_dim, 10, max_depth=args.max_depth).to(device)
    controller = MetaController(args.hidden_dim + 2, args.max_depth).to(device)

    model_optim = optim.Adam(model.parameters(), lr=args.lr)
    controller_optim = optim.Adam(controller.parameters(), lr=args.lr)

    ce_loss = nn.CrossEntropyLoss()
    baseline = None
    gamma_base = 0.95

    for epoch in range(1, args.epochs+1):
        model.train()
        epoch_rewards = []
        depths = []
        loop = tqdm(train_loader, desc=f"Epoch {epoch:02d}")
        for xb, yb in loop:
            xb, yb = xb.to(device), yb.to(device)
            # obs: mean embedding + zeros for loss & prev depth
            with torch.no_grad():
                emb = model.encoder(xb)
                emb_mean = emb.mean(dim=0)
            obs = torch.cat([emb_mean, torch.tensor([0.0, 0.0], device=device)], dim=0).unsqueeze(0)
            logits = controller(obs); probs = F.softmax(logits, dim=-1).squeeze(0)
            depth_idx = torch.multinomial(probs, num_samples=1).item(); chosen_depth = depth_idx + 1
            depths.append(chosen_depth)

            preds = model(xb, chosen_depth); loss = ce_loss(preds, yb)
            model_optim.zero_grad(); loss.backward(); model_optim.step()

            with torch.no_grad(): acc = accuracy(preds, yb)
            reward = acc - args.lambda_compute * (chosen_depth / args.max_depth)
            epoch_rewards.append(reward)

            logp = torch.log(probs[depth_idx] + 1e-10)
            if baseline is None: baseline = reward
            else: baseline = gamma_base * baseline + (1 - gamma_base) * reward
            adv = reward - baseline
            controller_optim.zero_grad(); policy_loss = -adv * logp; policy_loss.backward(); controller_optim.step()
            loop.set_postfix(avg_depth=sum(depths)/len(depths), recent_reward=sum(epoch_rewards)/len(epoch_rewards))

        # Eval
        model.eval()
        def eval_loader(loader):
            tot=0; n=0
            with torch.no_grad():
                for xb, yb in loader:
                    xb, yb = xb.to(device), yb.to(device)
                    emb = model.encoder(xb); emb_mean = emb.mean(dim=0)
                    obs = torch.cat([emb_mean, torch.tensor([0.0,0.0], device=device)], dim=0).unsqueeze(0)
                    probs = F.softmax(controller(obs).squeeze(0), dim=-1); depth_idx = probs.argmax().item(); d = depth_idx + 1
                    preds = model(xb, d)
                    tot += (preds.argmax(dim=1) == yb).sum().item(); n += yb.size(0)
            return tot / n

        train_acc = eval_loader(train_loader); test_acc = eval_loader(test_loader)
        print(f"Epoch {epoch:02d} SUMMARY -> Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Avg depth: {sum(depths)/len(depths):.2f} | Avg reward: {sum(epoch_rewards)/len(epoch_rewards):.4f}")

        # optionally save checkpoints
        if epoch % args.save_every == 0:
            os.makedirs(args.save_dir, exist_ok=True)
            torch.save(model.state_dict(), os.path.join(args.save_dir, f"model_epoch{epoch}.pth"))
            torch.save(controller.state_dict(), os.path.join(args.save_dir, f"controller_epoch{epoch}.pth"))

parser = argparse.ArgumentParser()
parser.add_argument("--epochs", type=int, default=12)
parser.add_argument("--batch-size", type=int, default=128)
parser.add_argument("--hidden-dim", type=int, default=256)
parser.add_argument("--lr", type=float, default=1e-3)
parser.add_argument("--max-depth", type=int, default=6)
parser.add_argument("--lambda-compute", type=float, default=0.04)
parser.add_argument("--save-every", type=int, default=5)
parser.add_argument("--save-dir", type=str, default="./checkpoints")
args = parser.parse_args([]) # Pass an empty list to parse_args
train(args)

# Commented out IPython magic to ensure Python compatibility.
# %pip install stable-baselines3 gym torch torchvision

# Commented out IPython magic to ensure Python compatibility.
# %pip install shimmy>=2.0

#!/usr/bin/env python3
# rrnn_ppo_per_sample.py
# Advanced: per-sample controller with PPO + branch selection
# Installs: pip install stable-baselines3 gym torch torchvision

import os, argparse, numpy as np
import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim
import torchvision.transforms as T, torchvision
from torch.utils.data import DataLoader
from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import DummyVecEnv
from gym import spaces, Env
from tqdm import tqdm

# ---------- Model parts ----------
class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self, h):
        r = F.relu(self.fc1(h)); r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class EncoderCIFAR(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(64, hidden_dim)
    def forward(self, x):
        h = self.conv(x).view(x.size(0), -1)
        return F.relu(self.fc(h))

class AdaptiveModelBranches(nn.Module):
    def __init__(self, hidden_dim, out_dim, max_depth=4, n_branches=3):
        super().__init__()
        self.encoder = EncoderCIFAR(hidden_dim)
        # create multiple branch variants for each depth slot
        self.branches = nn.ModuleList([
            nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)]) for _ in range(n_branches)
        ])
        self.predictor = nn.Linear(hidden_dim, out_dim)
        self.max_depth = max_depth
        self.n_branches = n_branches
    def forward(self, x, depth_choices, branch_choices):
        # depth_choices: (B,) depths (1..max_depth), branch_choices: (B,) branch index (0..n_branches-1)
        h = self.encoder(x)
        out_list = []
        for i in range(h.size(0)):
            hi = h[i:i+1]
            d = int(depth_choices[i])
            b = int(branch_choices[i])
            for j in range(d):
                hi = self.branches[b][j](hi)
            out_list.append(self.predictor(hi).squeeze(0))
        return torch.stack(out_list, dim=0)

# ---------- Gym env for per-sample RL ----------
class AdaptiveEnv(Env):
    def __init__(self, model, dataset_loader, device, max_depth=4, n_branches=3, lambda_compute=0.06):
        super().__init__()
        self.model = model
        self.loader = dataset_loader
        self.device = device
        self.max_depth = max_depth
        self.n_branches = n_branches
        self.lambda_compute = lambda_compute
        # Observation: encoder embedding (hidden_dim,) + target one-hot (10,)  -- simple
        hidden_dim = model.encoder.fc.out_features
        self.obs_dim = hidden_dim + 10
        # Action: depth (discrete max_depth) + branch (discrete n_branches) -> flattened into single discrete joint action
        self.action_space = spaces.MultiDiscrete([max_depth, n_branches])  # depth index [1..max_depth] as 1..D encoded, branch 0..B-1
        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.obs_dim,), dtype=np.float32)
        self.iter_loader = iter(self.loader)
    def reset(self):
        try:
            xb, yb = next(self.iter_loader)
        except StopIteration:
            self.iter_loader = iter(self.loader); xb, yb = next(self.iter_loader)
        self.curr_x = xb.to(self.device); self.curr_y = yb.to(self.device)
        with torch.no_grad():
            emb = self.model.encoder(self.curr_x)
            emb_mean = emb.mean(dim=0).cpu().numpy()
        # one-hot of label distribution for batch (simple)
        labels_onehot = np.zeros(10, dtype=np.float32)
        vals, counts = torch.unique(self.curr_y, return_counts=True)
        for v, c in zip(vals.cpu().numpy(), counts.cpu().numpy()): labels_onehot[int(v)] = c / self.curr_y.size(0)
        obs = np.concatenate([emb_mean, labels_onehot], axis=0).astype(np.float32)
        return obs
    def step(self, action):
        # action is array([depth_index, branch_index]) with 0-indexed values
        depth = int(action[0]) + 1  # map 0..D-1 -> depth 1..D
        branch = int(action[1])
        # produce outputs
        with torch.no_grad():
            preds = self.model(self.curr_x, torch.tensor([depth]*self.curr_x.size(0), device=self.device), torch.tensor([branch]*self.curr_x.size(0), device=self.device))
            acc = (preds.argmax(dim=1) == self.curr_y).float().mean().item()
        reward = acc - self.lambda_compute * (depth / self.max_depth)
        done = True  # one-step episode (simpler)
        info = {"accuracy": acc}
        # next observation for next reset
        try:
            xb, yb = next(self.iter_loader)
        except StopIteration:
            self.iter_loader = iter(self.loader); xb, yb = next(self.iter_loader)
        with torch.no_grad():
            emb = self.model.encoder(xb.to(self.device))
            emb_mean = emb.mean(dim=0).cpu().numpy()
        labels_onehot = np.zeros(10, dtype=np.float32)
        vals, counts = torch.unique(yb, return_counts=True)
        for v, c in zip(vals.cpu().numpy(), counts.cpu().numpy()): labels_onehot[int(v)] = c / yb.size(0)
        obs = np.concatenate([emb_mean, labels_onehot], axis=0).astype(np.float32)
        return obs, float(reward), done, info

# ---------- training loop: pretrain model; train PPO controller ----------
def main(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    transform = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)
    train_loader = DataLoader(trainset, batch_size=args.env_batch_size, shuffle=True, num_workers=4)
    model = AdaptiveModelBranches(args.hidden_dim, 10, max_depth=args.max_depth, n_branches=args.n_branches).to(device)

    # Pretrain predictor + encoder quickly on CIFAR-10 to stabilize features
    opt = optim.Adam(model.parameters(), lr=1e-3)
    ce = nn.CrossEntropyLoss()
    print("Pretraining model (short)...")
    for epoch in range(1,3):
        model.train()
        for xb, yb in tqdm(DataLoader(trainset, batch_size=128, shuffle=True), desc=f"pretrain {epoch}"):
            xb, yb = xb.to(device), yb.to(device)
            # random depth and branch for pretrain
            depths = torch.randint(1, args.max_depth+1, (xb.size(0),), device=device)
            branches = torch.randint(0, args.n_branches, (xb.size(0),), device=device)
            preds = model(xb, depths, branches)
            loss = ce(preds, yb)
            opt.zero_grad(); loss.backward(); opt.step()

    # Create env for PPO
    env = DummyVecEnv([lambda: AdaptiveEnv(model, DataLoader(trainset, batch_size=args.env_batch_size), device, max_depth=args.max_depth, n_branches=args.n_branches, lambda_compute=args.lambda_compute)])
    # Define discrete action shape mapping: we use MultiDiscrete; SB3 PPO needs a flattened discrete mapping. For simplicity, wrap MultiDiscrete as vector action (continuous) by using a custom policy network output and discrete sampling. To avoid extra wrappers, we'll use a small custom policy with MultiCategorical head inside stable-baselines3. For brevity we use the default MlpPolicy with action space as MultiDiscrete via SB3 custom policy registration - but here we keep example conceptual.

    # NOTE: implementing a fully correct SB3 MultiDiscrete categorical policy requires a bit of glue code.
    # To keep this script runnable out-of-the-box in many environments, we provide a fallback: use random policy sampling for several iterations,
    # and show how to integrate PPO offline with saved trajectories. For production, implement a custom SB3 policy that outputs MultiCategorical actions.

    print("Environment created. Running random policy demo (to test interaction & reward).")
    obs = env.reset()
    for step in range(20):
        # sample random actions for demo
        act = np.stack([np.random.randint(0, args.max_depth, size=(1,))[0], np.random.randint(0, args.n_branches, size=(1,))[0]])
        # SB3 wrapper expects shape (n_envs, action_shape) -> expand
        next_obs, rewards, dones, infos = env.step([act])
        print(f"Step {step}: reward={rewards[0]:.4f}, info={infos[0]}")

    # Save pretrain model
    os.makedirs(args.save_dir, exist_ok=True)
    torch.save(model.state_dict(), os.path.join(args.save_dir, "pretrained_rrnn_branches.pth"))
    print("Saved pretrained model.")

parser = argparse.ArgumentParser()
parser.add_argument("--hidden-dim", type=int, default=256)
parser.add_argument("--max-depth", type=int, default=4)
parser.add_argument("--n-branches", type=int, default=3)
parser.add_argument("--env-batch-size", type=int, default=32)
parser.add_argument("--lambda-compute", type=float, default=0.06)
parser.add_argument("--save-dir", type=str, default="./checkpoints")
args = parser.parse_args([]) # Pass an empty list to parse_args
main(args)

#!/usr/bin/env python3
# rrnn_per_sample_demo.py
# Requirements: torch, numpy, tqdm
# Run: python rrnn_per_sample_demo.py

import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim, random, numpy as np
from tqdm import trange

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Synthetic dataset (binary classification)
def make_synthetic_dataset(n_samples=2000, dim=24, noise=0.08):
    X = torch.randn(n_samples, dim)
    w = torch.randn(dim)
    logits = X @ w + 0.4 * (X[:, :4].pow(3).sum(dim=1))
    probs = torch.sigmoid(logits)
    y = (probs > 0.5).long()
    flip_mask = torch.rand(n_samples) < noise
    y[flip_mask] = 1 - y[flip_mask]
    return X, y

X, y = make_synthetic_dataset(2000, dim=24, noise=0.08)
train_X, train_y = X[:1600].to(device), y[:1600].to(device)
test_X, test_y = X[1600:].to(device), y[1600:].to(device)
print("Train size:", train_X.size(0), "Test size:", test_X.size(0))

# ---------- Model pieces ----------
class Encoder(nn.Module):
    def __init__(self, in_dim, hidden_dim):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))
    def forward(self, x): return F.relu(self.net(x))

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self, h):
        r = F.relu(self.fc1(h)); r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class Predictor(nn.Module):
    def __init__(self, dim, out_dim):
        super().__init__()
        self.head = nn.Sequential(nn.Linear(dim, max(dim//2, 8)), nn.ReLU(), nn.Linear(max(dim//2,8), out_dim))
    def forward(self, h): return self.head(h)

class AdaptiveModel(nn.Module):
    def __init__(self, in_dim, hidden_dim, out_dim, max_depth=5):
        super().__init__()
        self.encoder = Encoder(in_dim, hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = Predictor(hidden_dim, out_dim)
        self.max_depth = max_depth
    def forward_depths(self, x, depths):
        # depths: tensor (batch,) values in 1..max_depth
        batch_size = x.size(0)
        h = self.encoder(x)
        out = []
        for i in range(batch_size):
            hi = h[i:i+1]
            d = int(depths[i].item())
            for j in range(d):
                hi = self.core_blocks[j](hi)
            out.append(self.predictor(hi).squeeze(0))
        return torch.stack(out, dim=0)

# Meta-controller: per-sample logits
class MetaController(nn.Module):
    def __init__(self, obs_dim, max_depth):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(obs_dim, 128), nn.ReLU(), nn.Linear(128, max_depth))
    def forward(self, obs):  # obs: (batch, obs_dim)
        return self.net(obs)  # logits (batch, max_depth)

# Helpers
def compute_accuracy(preds, labels): return (preds.argmax(dim=1) == labels).float()

# ---------- Hyperparams ----------
in_dim = train_X.size(1)
hidden_dim = 64
out_dim = 2
max_depth = 5
batch_size = 64
epochs = 6
lambda_compute = 0.05

# ---------- Init ----------
model = AdaptiveModel(in_dim, hidden_dim, out_dim, max_depth=max_depth).to(device)
controller = MetaController(hidden_dim + 1, max_depth).to(device)
model_opt = optim.Adam(model.parameters(), lr=1e-3)
controller_opt = optim.Adam(controller.parameters(), lr=5e-4)
ce_loss = nn.CrossEntropyLoss(reduction='none')
baseline = 0.0
gamma = 0.95

# ---------- Training ----------
for epoch in range(1, epochs+1):
    perm = torch.randperm(train_X.size(0))
    model.train(); controller.train()
    epoch_rewards = []
    avg_depths = []
    for i in range(0, train_X.size(0), batch_size):
        idx = perm[i:i+batch_size]
        xb = train_X[idx]; yb = train_y[idx]
        B = xb.size(0)

        # per-sample encoder embedding as controller observation
        with torch.no_grad():
            emb = model.encoder(xb)  # (B, hidden_dim)
        obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)  # (B, hidden_dim+1)

        logits = controller(obs)            # (B, max_depth)
        probs = F.softmax(logits, dim=1)    # (B, max_depth)

        depths_idx = torch.multinomial(probs, num_samples=1).squeeze(1)  # 0..max_depth-1
        depths = depths_idx + 1  # 1..max_depth

        # Forward and supervised update
        preds = model.forward_depths(xb, depths)
        losses = ce_loss(preds, yb)  # (B,)
        model_opt.zero_grad(); losses.mean().backward(); model_opt.step()

        # Per-sample reward: indicator(correct) - compute_penalty
        with torch.no_grad():
            accs = compute_accuracy(preds, yb)         # (B,)
            rewards = accs - lambda_compute * (depths.float() / max_depth)
            rewards = rewards.cpu().numpy()

        # REINFORCE: log prob for chosen actions
        log_probs = torch.log(torch.gather(probs, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)  # (B,)
        batch_reward_mean = float(rewards.mean())
        baseline = gamma * baseline + (1-gamma) * batch_reward_mean
        advantages = torch.tensor(rewards - baseline, device=device, dtype=torch.float32)

        controller_opt.zero_grad()
        policy_loss = - (advantages * log_probs).mean()
        policy_loss.backward()
        controller_opt.step()

        epoch_rewards.append(batch_reward_mean)
        avg_depths.append(depths.float().mean().item())

        # Print first batch's per-sample probs & chosen depths
        if i == 0:
            to_print = min(6, B)
            print(f"\nEpoch {epoch} batch {i//batch_size}: sample controller probs & chosen depths (first {to_print} samples)")
            probs_cpu = probs[:to_print].detach().cpu().numpy()
            depths_cpu = depths[:to_print].detach().cpu().numpy()
            for s in range(to_print):
                print(f" Sample {s}: probs={np.round(probs_cpu[s], 3)} -> chosen_depth={int(depths_cpu[s])}")

    # Evaluation (greedy controller)
    model.eval(); controller.eval()
    tot=0; n=0; depth_sum=0.0
    with torch.no_grad():
        for i in range(0, test_X.size(0), batch_size):
            xb = test_X[i:i+batch_size]; yb = test_y[i:i+batch_size]; B = xb.size(0)
            emb = model.encoder(xb)
            obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
            probs = F.softmax(controller(obs), dim=1)
            depth_idx = probs.argmax(dim=1)
            depths = depth_idx + 1
            preds = model.forward_depths(xb, depths)
            tot += (preds.argmax(dim=1) == yb).sum().item(); n += B
            depth_sum += depths.float().sum().item()
    test_acc = tot / n
    avg_depth_test = depth_sum / n
    print(f"\nEpoch {epoch} summary -> Avg train reward: {sum(epoch_rewards)/len(epoch_rewards):.4f}, Avg depth(train): {sum(avg_depths)/len(avg_depths):.2f}")
    print(f" Test Acc: {test_acc:.4f}, Avg depth(test greedy): {avg_depth_test:.2f}")

# Save checkpoints
torch.save(model.state_dict(), "adaptive_model_per_sample.pth")
torch.save(controller.state_dict(), "controller_per_sample.pth")
print("\\nSaved model checkpoints: adaptive_model_per_sample.pth, controller_per_sample.pth")

#!/usr/bin/env python3
# rrnn_per_sample_ppo.py
# Requirements: torch, numpy, tqdm
# Run: python rrnn_per_sample_ppo.py

import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim, numpy as np, random, time
from tqdm import trange

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Device:", device)

# Synthetic dataset for quick experiments (replace with CIFAR loader for real tasks)
def make_synthetic_dataset(n_samples=2000, dim=24, noise=0.08):
    X = torch.randn(n_samples, dim)
    w = torch.randn(dim)
    logits = X @ w + 0.4 * (X[:, :4].pow(3).sum(dim=1))
    probs = torch.sigmoid(logits)
    y = (probs > 0.5).long()
    flip_mask = torch.rand(n_samples) < noise
    y[flip_mask] = 1 - y[flip_mask]
    return X, y

# ---------- Model pieces ----------
class Encoder(nn.Module):
    def __init__(self, in_dim, hidden_dim):
        super().__init__()
        self.net = nn.Sequential(nn.Linear(in_dim, hidden_dim), nn.ReLU(), nn.Linear(hidden_dim, hidden_dim))
    def forward(self, x): return F.relu(self.net(x))

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self, h):
        r = F.relu(self.fc1(h)); r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class Predictor(nn.Module):
    def __init__(self, dim, out_dim):
        super().__init__()
        self.head = nn.Sequential(nn.Linear(dim, max(dim//2, 8)), nn.ReLU(), nn.Linear(max(dim//2,8), out_dim))
    def forward(self, h): return self.head(h)

class AdaptiveModel(nn.Module):
    def __init__(self, in_dim, hidden_dim, out_dim, max_depth=5):
        super().__init__()
        self.encoder = Encoder(in_dim, hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = Predictor(hidden_dim, out_dim)
        self.max_depth = max_depth
    def forward_depths(self, x, depths):
        batch_size = x.size(0)
        h = self.encoder(x)
        out = []
        for i in range(batch_size):
            hi = h[i:i+1]
            d = int(depths[i].item())
            for j in range(d):
                hi = self.core_blocks[j](hi)
            out.append(self.predictor(hi).squeeze(0))
        return torch.stack(out, dim=0)

# ---------- Actor-Critic controller (PPO-style) ----------
class ControllerAC(nn.Module):
    def __init__(self, obs_dim, max_depth):
        super().__init__()
        self.shared = nn.Sequential(nn.Linear(obs_dim, 128), nn.ReLU())
        self.actor = nn.Linear(128, max_depth)   # logits per depth
        self.critic = nn.Linear(128, 1)          # value estimate
    def forward(self, obs):
        h = self.shared(obs)
        logits = self.actor(h)
        value = self.critic(h).squeeze(1)
        return logits, value

# ---------- Helpers ----------
def compute_accuracy(preds, labels): return (preds.argmax(dim=1) == labels).float()

# ---------- Hyperparameters (tune these) ----------
in_dim = 24
hidden_dim = 64
out_dim = 2
max_depth = 5
batch_size = 64
epochs = 8
lambda_compute = 0.05

# PPO hyperparams
ppo_epochs = 4
clip_eps = 0.2
vf_coef = 1.0
ent_coef = 0.01
actor_lr = 3e-4
model_lr = 1e-3

# ---------- Init ----------
X, y = make_synthetic_dataset(n_samples=2000, dim=in_dim, noise=0.08)
train_X, train_y = X[:1600].to(device), y[:1600].to(device)
test_X, test_y = X[1600:].to(device), y[1600:].to(device)

model = AdaptiveModel(in_dim, hidden_dim, out_dim, max_depth=max_depth).to(device)
controller = ControllerAC(hidden_dim + 1, max_depth).to(device)
model_opt = optim.Adam(model.parameters(), lr=model_lr)
controller_opt = optim.Adam(controller.parameters(), lr=actor_lr)
ce_loss = nn.CrossEntropyLoss(reduction='none')

# ---------- Training loop ----------
for epoch in range(1, epochs+1):
    perm = torch.randperm(train_X.size(0))
    model.train(); controller.train()
    epoch_rewards = []; avg_depths = []
    t0 = time.time()
    for i in range(0, train_X.size(0), batch_size):
        idx = perm[i:i+batch_size]
        xb = train_X[idx]; yb = train_y[idx]; B = xb.size(0)

        # Controller observations: per-sample embeddings + a scalar
        with torch.no_grad():
            emb = model.encoder(xb)
        obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)

        # Actor-critic forward
        logits, values = controller(obs)           # logits (B,D), values (B)
        probs = F.softmax(logits, dim=1)
        depths_idx = torch.multinomial(probs, num_samples=1).squeeze(1)  # 0..D-1
        depths = depths_idx + 1

        # Model forward and supervised update
        preds = model.forward_depths(xb, depths)
        losses = ce_loss(preds, yb)
        model_opt.zero_grad(); losses.mean().backward(); model_opt.step()

        # Compute rewards (acc - depth penalty)
        with torch.no_grad():
            accs = compute_accuracy(preds, yb)
            rewards = accs - lambda_compute * (depths.float() / max_depth)

        rewards_t = rewards.to(device).float()

        # Old log probs must be computed from detached logits
        old_logits = logits.detach()
        old_probs = F.softmax(old_logits, dim=1)
        old_log_probs = torch.log(torch.gather(old_probs, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)

        # Advantages = R - V (one-step)
        advantages = rewards_t - values.detach()

        # PPO update: multiple epochs over this batch
        for _ in range(ppo_epochs):
            logits_new, values_new = controller(obs)
            probs_new = F.softmax(logits_new, dim=1)
            logp_new = torch.log(torch.gather(probs_new, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)

            ratio = torch.exp(logp_new - old_log_probs)
            surr1 = ratio * advantages
            surr2 = torch.clamp(ratio, 1.0 - clip_eps, 1.0 + clip_eps) * advantages
            policy_loss = - torch.mean(torch.min(surr1, surr2))

            value_loss = F.mse_loss(values_new, rewards_t)
            entropy = -torch.mean(torch.sum(probs_new * torch.log(probs_new + 1e-10), dim=1))

            loss = policy_loss + vf_coef * value_loss - ent_coef * entropy

            controller_opt.zero_grad()
            loss.backward()
            controller_opt.step()

        epoch_rewards.append(float(rewards_t.mean().item()))
        avg_depths.append(float(depths.float().mean().item()))

        # Print controller probs & chosen depths for first batch of epoch
        if i == 0:
            to_print = min(6, B)
            probs_cpu = probs[:to_print].detach().cpu().numpy()
            depths_cpu = depths[:to_print].detach().cpu().numpy()
            print(f"\nEpoch {epoch} batch {i//batch_size}: sample controller probs & chosen depths (first {to_print} samples)")
            for s in range(to_print):
                print(f" Sample {s}: probs={np.round(probs_cpu[s], 3)} -> chosen_depth={int(depths_cpu[s])}")

    # Evaluation (greedy per-sample depth)
    model.eval(); controller.eval()
    tot=0; n=0; depth_sum=0.0
    with torch.no_grad():
        for i in range(0, test_X.size(0), batch_size):
            xb = test_X[i:i+batch_size]; yb = test_y[i:i+batch_size]; B = xb.size(0)
            emb = model.encoder(xb); obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
            logits, _ = controller(obs); probs = F.softmax(logits, dim=1)
            depth_idx = probs.argmax(dim=1); depths = depth_idx + 1
            preds = model.forward_depths(xb, depths)
            tot += (preds.argmax(dim=1) == yb).sum().item(); n += B
            depth_sum += depths.float().sum().item()
    test_acc = tot / n
    avg_depth_test = depth_sum / n
    print(f"\nEpoch {epoch} summary -> Avg train reward: {sum(epoch_rewards)/len(epoch_rewards):.4f}, Avg depth(train): {sum(avg_depths)/len(avg_depths):.2f}")
    print(f" Test Acc: {test_acc:.4f}, Avg depth(test greedy): {avg_depth_test:.2f} | epoch time: {time.time()-t0:.2f}s")

# Save
torch.save(model.state_dict(), "adaptive_model_ppo.pth")
torch.save(controller.state_dict(), "controller_ppo.pth")
print("Saved model checkpoints: adaptive_model_ppo.pth, controller_ppo.pth")

# Commented out IPython magic to ensure Python compatibility.
# 
# # in a Colab cell (bash)
# !pip install torch torchvision matplotlib tqdm
# # create the script
# %%bash
# cat > rrnn_cifar10_with_graphs.py <<'PY'
# # (paste the entire script content from above here)
# PY

# run for a quick demo (smaller epochs if you want)
!python rrnn_cifar10_with_graphs.py --epochs 8 --batch-size 128 --hidden-dim 128 --max-depth 5 --save-dir ./rrnn_colab_out

from IPython.display import Image, display
display(Image('./rrnn_colab_out/accuracy_vs_epoch.png'))
display(Image('./rrnn_colab_out/avg_depth_vs_epoch.png'))
display(Image('./rrnn_colab_out/reward_vs_epoch.png'))
display(Image('./rrnn_colab_out/depth_hist_epoch_8.png'))

#!/usr/bin/env python3
# rrnn_cifar10_with_graphs.py
# Requirements: torch, torchvision, matplotlib, numpy, tqdm
# Usage (local/GPU): python rrnn_cifar10_with_graphs.py --epochs 20 --batch-size 128 --max-depth 5
#
# This script trains a conv encoder + Ramanujan recursive core. A PPO-style
# actor-critic controller chooses a per-sample recursion depth each forward.
# At the end it saves 4 PNG graphs:
#  - accuracy_vs_epoch.png
#  - avg_depth_vs_epoch.png
#  - reward_vs_epoch.png
#  - depth_hist_epoch_{N}.png

import argparse, os, time, numpy as np
import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim
import torchvision.transforms as T, torchvision
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from tqdm import tqdm

# ----------------- model components -----------------
class EncoderConv(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(128, hidden_dim)
    def forward(self, x):
        h = self.conv(x).view(x.size(0), -1)
        return F.relu(self.fc(h))

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self, h):
        r = F.relu(self.fc1(h)); r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class Predictor(nn.Module):
    def __init__(self, dim, out_dim):
        super().__init__()
        self.head = nn.Sequential(nn.Linear(dim, dim//2), nn.ReLU(), nn.Linear(dim//2, out_dim))
    def forward(self, h):
        return self.head(h)

class AdaptiveModel(nn.Module):
    def __init__(self, hidden_dim, out_dim, max_depth=5):
        super().__init__()
        self.encoder = EncoderConv(hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = Predictor(hidden_dim, out_dim)
        self.max_depth = max_depth
    def forward_depths(self, x, depths):
        batch_size = x.size(0)
        h = self.encoder(x)
        out = []
        for i in range(batch_size):
            hi = h[i:i+1]
            d = int(depths[i].item())
            for j in range(d):
                hi = self.core_blocks[j](hi)
            out.append(self.predictor(hi).squeeze(0))
        return torch.stack(out, dim=0)

class ControllerAC(nn.Module):
    def __init__(self, obs_dim, max_depth):
        super().__init__()
        self.shared = nn.Sequential(nn.Linear(obs_dim, 256), nn.ReLU())
        self.actor = nn.Linear(256, max_depth)
        self.critic = nn.Linear(256, 1)
    def forward(self, obs):
        h = self.shared(obs)
        logits = self.actor(h)
        value = self.critic(h).squeeze(1)
        return logits, value

# ----------------- helpers -----------------
def compute_accuracy(preds, labels):
    return (preds.argmax(dim=1) == labels).float()

# ----------------- training script -----------------
def main(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    transform_train = T.Compose([T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(), T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    transform_test  = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    train_loader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    test_loader  = DataLoader(testset,  batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)

    model = AdaptiveModel(args.hidden_dim, 10, max_depth=args.max_depth).to(device)
    controller = ControllerAC(args.hidden_dim + 1, args.max_depth).to(device)
    model_opt = optim.Adam(model.parameters(), lr=args.model_lr)
    controller_opt = optim.Adam(controller.parameters(), lr=args.actor_lr)
    ce_loss = nn.CrossEntropyLoss(reduction='none')

    # logging arrays
    epochs_list=[]; train_acc_list=[]; test_acc_list=[]; avg_depth_train_list=[]; avg_depth_test_list=[]; reward_list=[]

    for epoch in range(1, args.epochs+1):
        model.train(); controller.train()
        epoch_rewards=[]; epoch_depths=[]
        t0 = time.time()
        for xb, yb in tqdm(train_loader, desc=f"Epoch {epoch}"):
            xb, yb = xb.to(device), yb.to(device)
            B = xb.size(0)
            # controller obs = encoder embedding + scalar
            with torch.no_grad():
                emb = model.encoder(xb)
            obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
            logits, values = controller(obs)
            probs = F.softmax(logits, dim=1)
            depths_idx = torch.multinomial(probs, num_samples=1).squeeze(1)
            depths = depths_idx + 1
            # supervised forward/backprop
            preds = model.forward_depths(xb, depths)
            losses = ce_loss(preds, yb)
            model_opt.zero_grad(); losses.mean().backward(); model_opt.step()
            # rewards
            with torch.no_grad():
                accs = compute_accuracy(preds, yb)
                rewards = accs - args.lambda_compute * (depths.float() / args.max_depth)
            rewards_t = rewards.to(device).float()
            # PPO-style update (batch treated as 1-step trajectories)
            old_logits = logits.detach(); old_probs = F.softmax(old_logits, dim=1)
            old_log_probs = torch.log(torch.gather(old_probs, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)
            advantages = rewards_t - values.detach()
            for _ in range(args.ppo_epochs):
                logits_new, values_new = controller(obs)
                probs_new = F.softmax(logits_new, dim=1)
                logp_new = torch.log(torch.gather(probs_new, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)
                ratio = torch.exp(logp_new - old_log_probs)
                surr1 = ratio * advantages
                surr2 = torch.clamp(ratio, 1.0 - args.clip_eps, 1.0 + args.clip_eps) * advantages
                policy_loss = - torch.mean(torch.min(surr1, surr2))
                value_loss = F.mse_loss(values_new, rewards_t)
                entropy = -torch.mean(torch.sum(probs_new * torch.log(probs_new + 1e-10), dim=1))
                loss = policy_loss + args.vf_coef * value_loss - args.ent_coef * entropy
                controller_opt.zero_grad(); loss.backward(); controller_opt.step()
            epoch_rewards.append(float(rewards_t.mean().item()))
            epoch_depths.append(float(depths.float().mean().item()))

        # evaluation (greedy per-sample)
        model.eval(); controller.eval()
        # train eval
        tot=0; n=0; depth_sum=0.0
        with torch.no_grad():
            for xb, yb in train_loader:
                xb, yb = xb.to(device), yb.to(device)
                B = xb.size(0)
                emb = model.encoder(xb)
                obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
                logits, _ = controller(obs)
                probs = F.softmax(logits, dim=1)
                depth_idx = probs.argmax(dim=1); depths = depth_idx + 1
                preds = model.forward_depths(xb, depths)
                tot += (preds.argmax(dim=1) == yb).sum().item(); n += B; depth_sum += depths.float().sum().item()
        train_acc = tot / n; avg_depth_train = depth_sum / n
        # test eval
        tot=0; n=0; depth_sum=0.0; depth_counts=[]
        with torch.no_grad():
            for xb, yb in test_loader:
                xb, yb = xb.to(device), yb.to(device)
                B = xb.size(0)
                emb = model.encoder(xb)
                obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
                logits, _ = controller(obs)
                probs = F.softmax(logits, dim=1)
                depth_idx = probs.argmax(dim=1); depths = depth_idx + 1
                preds = model.forward_depths(xb, depths)
                tot += (preds.argmax(dim=1) == yb).sum().item(); n += B; depth_sum += depths.float().sum().item()
                depth_counts.extend(depths.cpu().numpy().tolist())
        test_acc = tot / n; avg_depth_test = depth_sum / n
        depth_hist_final = np.array(depth_counts)

        epochs_list.append(epoch); train_acc_list.append(train_acc); test_acc_list.append(test_acc)
        avg_depth_train_list.append(avg_depth_train); avg_depth_test_list.append(avg_depth_test)
        reward_list.append(sum(epoch_rewards)/len(epoch_rewards) if len(epoch_rewards)>0 else 0.0)

        print(f"Epoch {epoch} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Avg depth train: {avg_depth_train:.2f} | Avg depth test: {avg_depth_test:.2f} | Avg reward: {reward_list[-1]:.4f} | epoch time: {time.time()-t0:.2f}s")

        # optionally save per-epoch checkpoints
        if args.save_every and epoch % args.save_every == 0:
            os.makedirs(args.save_dir, exist_ok=True)
            torch.save(model.state_dict(), os.path.join(args.save_dir, f"model_epoch{epoch}.pth"))
            torch.save(controller.state_dict(), os.path.join(args.save_dir, f"controller_epoch{epoch}.pth"))

    # final plotting (after all epochs)
    os.makedirs(args.save_dir, exist_ok=True)
    # accuracy vs epoch
    plt.figure(); plt.plot(epochs_list, train_acc_list, marker='o'); plt.plot(epochs_list, test_acc_list, marker='o'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy vs Epoch'); plt.legend(['Train','Test']); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, "accuracy_vs_epoch.png"))
    # avg depth vs epoch
    plt.figure(); plt.plot(epochs_list, avg_depth_train_list, marker='o'); plt.plot(epochs_list, avg_depth_test_list, marker='o'); plt.xlabel('Epoch'); plt.ylabel('Avg Depth'); plt.title('Avg Depth vs Epoch'); plt.legend(['Train','Test']); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, "avg_depth_vs_epoch.png"))
    # reward vs epoch
    plt.figure(); plt.plot(epochs_list, reward_list, marker='o'); plt.xlabel('Epoch'); plt.ylabel('Avg Reward'); plt.title('Avg Reward vs Epoch'); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, "reward_vs_epoch.png"))
    # depth histogram final epoch
    plt.figure(); plt.hist(depth_hist_final, bins=np.arange(1, args.max_depth+2)-0.5); plt.xlabel('Depth'); plt.ylabel('Count'); plt.title('Depth distribution (test greedy)'); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, f"depth_hist_epoch_{args.epochs}.png"))

    # save final models
    torch.save(model.state_dict(), os.path.join(args.save_dir, "adaptive_model_final.pth"))
    torch.save(controller.state_dict(), os.path.join(args.save_dir, "controller_final.pth"))
    print("Saved graphs and models to", args.save_dir)

parser = argparse.ArgumentParser()
parser.add_argument("--epochs", type=int, default=12)
parser.add_argument("--batch-size", type=int, default=128)
parser.add_argument("--hidden-dim", type=int, default=256)
parser.add_argument("--model-lr", type=float, default=1e-3)
parser.add_argument("--actor-lr", type=float, default=3e-4)
parser.add_argument("--max-depth", type=int, default=5)
parser.add_argument("--lambda-compute", type=float, default=0.04)
parser.add_argument("--ppo-epochs", type=int, default=3)
parser.add_argument("--clip-eps", type=float, default=0.2)
parser.add_argument("--vf-coef", type=float, default=1.0)
parser.add_argument("--ent-coef", type=float, default=0.01)
parser.add_argument("--save-every", type=int, default=5)
parser.add_argument("--save-dir", type=str, default="./rrnn_checkpoints")
args = parser.parse_args([])
main(args)

#!/usr/bin/env python3
# rrnn_cifar10_adaptive_full.py
# Requirements: torch, torchvision, matplotlib, numpy, tqdm
# Usage: python rrnn_cifar10_adaptive_full.py --epochs 12 --batch-size 128 --max-depth 5

import argparse, os, time, numpy as np
import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim
import torchvision.transforms as T, torchvision
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
from tqdm import tqdm

# ----------------- Model components -----------------
class EncoderConv(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(128, hidden_dim)
    def forward(self, x):
        h = self.conv(x).view(x.size(0), -1)
        return F.relu(self.fc(h))

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self, h):
        r = F.relu(self.fc1(h))
        r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class Predictor(nn.Module):
    def __init__(self, dim, out_dim):
        super().__init__()
        self.head = nn.Sequential(nn.Linear(dim, dim//2), nn.ReLU(), nn.Linear(dim//2, out_dim))
    def forward(self, h):
        return self.head(h)

class AdaptiveModel(nn.Module):
    def __init__(self, hidden_dim, out_dim, max_depth=5):
        super().__init__()
        self.encoder = EncoderConv(hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = Predictor(hidden_dim, out_dim)
        self.max_depth = max_depth

    def forward_depths(self, x, depths):
        batch_size = x.size(0)
        h = self.encoder(x)
        out = []
        for i in range(batch_size):
            hi = h[i:i+1]
            d = int(depths[i].item())
            for j in range(d):
                hi = self.core_blocks[j](hi)
            out.append(self.predictor(hi).squeeze(0))
        return torch.stack(out, dim=0)

class ControllerAC(nn.Module):
    def __init__(self, obs_dim, max_depth):
        super().__init__()
        self.shared = nn.Sequential(nn.Linear(obs_dim, 256), nn.ReLU())
        self.actor = nn.Linear(256, max_depth)
        self.critic = nn.Linear(256, 1)
    def forward(self, obs):
        h = self.shared(obs)
        logits = self.actor(h)
        value = self.critic(h).squeeze(1)
        return logits, value

# ----------------- Helpers -----------------
def compute_accuracy(preds, labels):
    return (preds.argmax(dim=1) == labels).float()

# ----------------- Training -----------------
def main(args):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    transform_train = T.Compose([T.RandomCrop(32, padding=4), T.RandomHorizontalFlip(),
                                 T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    transform_test  = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3, (0.5,)*3)])
    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
    testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
    train_loader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True, num_workers=4, pin_memory=True)
    test_loader  = DataLoader(testset,  batch_size=args.batch_size, shuffle=False, num_workers=4, pin_memory=True)

    model = AdaptiveModel(args.hidden_dim, 10, max_depth=args.max_depth).to(device)
    controller = ControllerAC(args.hidden_dim + 1, args.max_depth).to(device)
    model_opt = optim.Adam(model.parameters(), lr=args.model_lr)
    controller_opt = optim.Adam(controller.parameters(), lr=args.actor_lr)
    ce_loss = nn.CrossEntropyLoss(reduction='none')

    # Logging
    epochs_list=[]; train_acc_list=[]; test_acc_list=[]; avg_depth_train_list=[]; avg_depth_test_list=[]; reward_list=[]
    depth_hist_per_epoch = {}

    for epoch in range(1, args.epochs+1):
        model.train(); controller.train()
        epoch_rewards=[]; epoch_depths=[]
        t0 = time.time()
        for xb, yb in tqdm(train_loader, desc=f"Epoch {epoch}"):
            xb, yb = xb.to(device), yb.to(device)
            B = xb.size(0)
            with torch.no_grad():
                emb = model.encoder(xb)
            obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
            logits, values = controller(obs)
            probs = F.softmax(logits, dim=1)
            depths_idx = torch.multinomial(probs, num_samples=1).squeeze(1)
            depths = depths_idx + 1

            # Log depth histogram
            if epoch not in depth_hist_per_epoch:
                depth_hist_per_epoch[epoch] = []
            depth_hist_per_epoch[epoch].extend(depths.cpu().numpy().tolist())

            # Supervised forward/backward
            preds = model.forward_depths(xb, depths)
            losses = ce_loss(preds, yb)
            model_opt.zero_grad(); losses.mean().backward(); model_opt.step()

            # Rewards
            with torch.no_grad():
                accs = compute_accuracy(preds, yb)
                rewards = accs - args.lambda_compute * (depths.float() / args.max_depth)
            rewards_t = rewards.to(device).float()

            # PPO-style update
            old_logits = logits.detach(); old_probs = F.softmax(old_logits, dim=1)
            old_log_probs = torch.log(torch.gather(old_probs, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)
            advantages = rewards_t - values.detach()
            for _ in range(args.ppo_epochs):
                logits_new, values_new = controller(obs)
                probs_new = F.softmax(logits_new, dim=1)
                logp_new = torch.log(torch.gather(probs_new, 1, depths_idx.unsqueeze(1)).squeeze(1) + 1e-10)
                ratio = torch.exp(logp_new - old_log_probs)
                surr1 = ratio * advantages
                surr2 = torch.clamp(ratio, 1.0 - args.clip_eps, 1.0 + args.clip_eps) * advantages
                policy_loss = - torch.mean(torch.min(surr1, surr2))
                value_loss = F.mse_loss(values_new, rewards_t)
                entropy = -torch.mean(torch.sum(probs_new * torch.log(probs_new + 1e-10), dim=1))
                loss = policy_loss + args.vf_coef * value_loss - args.ent_coef * entropy
                controller_opt.zero_grad(); loss.backward(); controller_opt.step()

            epoch_rewards.append(float(rewards_t.mean().item()))
            epoch_depths.append(float(depths.float().mean().item()))

        # Evaluation (greedy)
        model.eval(); controller.eval()
        def eval_loader(loader):
            tot=0; n=0; depth_sum=0.0
            with torch.no_grad():
                for xb, yb in loader:
                    xb, yb = xb.to(device), yb.to(device)
                    B = xb.size(0)
                    emb = model.encoder(xb)
                    obs = torch.cat([emb, torch.zeros(B,1, device=device)], dim=1)
                    logits, _ = controller(obs)
                    probs = F.softmax(logits, dim=1)
                    depth_idx = probs.argmax(dim=1); depths = depth_idx + 1
                    preds = model.forward_depths(xb, depths)
                    tot += (preds.argmax(dim=1) == yb).sum().item(); n += B; depth_sum += depths.float().sum().item()
            return tot / n, depth_sum / n
        train_acc, avg_depth_train = eval_loader(train_loader)
        test_acc, avg_depth_test = eval_loader(test_loader)

        # Logging
        epochs_list.append(epoch); train_acc_list.append(train_acc); test_acc_list.append(test_acc)
        avg_depth_train_list.append(avg_depth_train); avg_depth_test_list.append(avg_depth_test)
        reward_list.append(sum(epoch_rewards)/len(epoch_rewards) if len(epoch_rewards)>0 else 0.0)

        print(f"Epoch {epoch} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Avg depth train: {avg_depth_train:.2f} | Avg depth test: {avg_depth_test:.2f} | Avg reward: {reward_list[-1]:.4f} | epoch time: {time.time()-t0:.2f}s")

        # Save checkpoints
        if args.save_every and epoch % args.save_every == 0:
            os.makedirs(args.save_dir, exist_ok=True)
            torch.save(model.state_dict(), os.path.join(args.save_dir, f"model_epoch{epoch}.pth"))
            torch.save(controller.state_dict(), os.path.join(args.save_dir, f"controller_epoch{epoch}.pth"))

    # ----------------- Plotting -----------------
    os.makedirs(args.save_dir, exist_ok=True)
    # Accuracy
    plt.figure(); plt.plot(epochs_list, train_acc_list, 'o-'); plt.plot(epochs_list, test_acc_list, 'o-')
    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy vs Epoch'); plt.legend(['Train','Test']); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, "accuracy_vs_epoch.png"))
    # Avg depth
    plt.figure(); plt.plot(epochs_list, avg_depth_train_list, 'o-'); plt.plot(epochs_list, avg_depth_test_list, 'o-')
    plt.xlabel('Epoch'); plt.ylabel('Avg Depth'); plt.title('Avg Depth vs Epoch'); plt.legend(['Train','Test']); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, "avg_depth_vs_epoch.png"))
    # Reward
    plt.figure(); plt.plot(epochs_list, reward_list, 'o-'); plt.xlabel('Epoch'); plt.ylabel('Avg Reward'); plt.title('Avg Reward vs Epoch'); plt.grid(True)
    plt.savefig(os.path.join(args.save_dir, "reward_vs_epoch.png"))
    # Depth histograms per epoch
    for e in depth_hist_per_epoch:
        plt.figure(); plt.hist(depth_hist_per_epoch[e], bins=np.arange(1, args.max_depth+2)-0.5)
        plt.xlabel('Depth'); plt.ylabel('Count'); plt.title(f'Depth histogram epoch {e}'); plt.grid(True)
        plt.savefig(os.path.join(args.save_dir, f"depth_hist_epoch_{e}.png"))

    # Save final models
    torch.save(model.state_dict(), os.path.join(args.save_dir, "adaptive_model_final.pth"))
    torch.save(controller.state_dict(), os.path.join(args.save_dir, "controller_final.pth"))
    print("Saved all graphs and models to", args.save_dir)

# ----------------- Argument Parser -----------------
parser = argparse.ArgumentParser()
parser.add_argument("--epochs", type=int, default=12)
parser.add_argument("--batch-size", type=int, default=128)
parser.add_argument("--hidden-dim", type=int, default=256)
parser.add_argument("--model-lr", type=float, default=1e-3)
parser.add_argument("--actor-lr", type=float, default=3e-4)
parser.add_argument("--max-depth", type=int, default=5)
parser.add_argument("--lambda-compute", type=float, default=0.01)  # smaller penalty
parser.add_argument("--ppo-epochs", type=int, default=4)
parser.add_argument("--clip-eps", type=float, default=0.2)
parser.add_argument("--vf-coef", type=float, default=1.0)
parser.add_argument("--ent-coef", type=float, default=0.05)        # encourages exploration
parser.add_argument("--save-every", type=int, default=5)
parser.add_argument("--save-dir", type=str, default="./rrnn_checkpoints")
args = parser.parse_args([])
main(args)

# ====================================================
# RRNN CIFAR-10 Per-sample Adaptive Depth Notebook
# ====================================================

# Install required packages (Colab usually has torch, torchvision, matplotlib)
!pip install --quiet tqdm

# ----------------- Imports -----------------
import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim
import torchvision, torchvision.transforms as T
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
import os, time

# ----------------- Model Definitions -----------------
class EncoderConv(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(128, hidden_dim)
    def forward(self,x):
        h = self.conv(x).view(x.size(0),-1)
        return F.relu(self.fc(h))

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim,dim)
        self.fc2 = nn.Linear(dim,dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))
    def forward(self,h):
        r = F.relu(self.fc1(h))
        r = self.fc2(r)
        return (1-torch.sigmoid(self.alpha))*h + torch.sigmoid(self.alpha)*(h+r)

class Predictor(nn.Module):
    def __init__(self, dim, out_dim):
        super().__init__()
        self.head = nn.Sequential(nn.Linear(dim,dim//2), nn.ReLU(), nn.Linear(dim//2,out_dim))
    def forward(self,h): return self.head(h)

class AdaptiveModel(nn.Module):
    def __init__(self, hidden_dim, out_dim, max_depth=5):
        super().__init__()
        self.encoder = EncoderConv(hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = Predictor(hidden_dim, out_dim)
        self.max_depth = max_depth
    def forward_depths(self, x, depths):
        batch_size = x.size(0)
        h = self.encoder(x)
        out = []
        for i in range(batch_size):
            hi = h[i:i+1]
            d = int(depths[i].item())
            for j in range(d):
                hi = self.core_blocks[j](hi)
            out.append(self.predictor(hi).squeeze(0))
        return torch.stack(out, dim=0)

class ControllerAC(nn.Module):
    def __init__(self, obs_dim, max_depth):
        super().__init__()
        self.shared = nn.Sequential(nn.Linear(obs_dim,256), nn.ReLU())
        self.actor = nn.Linear(256,max_depth)
        self.critic = nn.Linear(256,1)
    def forward(self, obs):
        h = self.shared(obs)
        logits = self.actor(h)
        value = self.critic(h).squeeze(1)
        return logits, value

# ----------------- Helper -----------------
def compute_accuracy(preds, labels):
    return (preds.argmax(dim=1) == labels).float()

# ----------------- Hyperparameters -----------------
args = {
    "epochs": 8,
    "batch_size": 128,
    "hidden_dim": 256,
    "max_depth": 5,
    "lambda_compute": 0.01,
    "ppo_epochs": 4,
    "clip_eps": 0.2,
    "vf_coef": 1.0,
    "ent_coef": 0.05,
    "model_lr": 1e-3,
    "actor_lr": 3e-4,
    "save_dir": "./rrnn_colab_out"
}

os.makedirs(args["save_dir"], exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ----------------- Data -----------------
transform_train = T.Compose([T.RandomCrop(32,padding=4), T.RandomHorizontalFlip(),
                             T.ToTensor(), T.Normalize((0.5,)*3,(0.5,)*3)])
transform_test = T.Compose([T.ToTensor(), T.Normalize((0.5,)*3,(0.5,)*3)])
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)
testset  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
train_loader = DataLoader(trainset, batch_size=args["batch_size"], shuffle=True, num_workers=2)
test_loader  = DataLoader(testset, batch_size=args["batch_size"], shuffle=False, num_workers=2)

# ----------------- Model -----------------
model = AdaptiveModel(args["hidden_dim"], 10, args["max_depth"]).to(device)
controller = ControllerAC(args["hidden_dim"]+1, args["max_depth"]).to(device)
model_opt = optim.Adam(model.parameters(), lr=args["model_lr"])
controller_opt = optim.Adam(controller.parameters(), lr=args["actor_lr"])
ce_loss = nn.CrossEntropyLoss(reduction='none')

# ----------------- Logging -----------------
epochs_list=[]; train_acc_list=[]; test_acc_list=[]
avg_depth_train_list=[]; avg_depth_test_list=[]; reward_list=[]
depth_hist_per_epoch={}

# ----------------- Training Loop -----------------
for epoch in range(1,args["epochs"]+1):
    model.train(); controller.train()
    epoch_rewards=[]; epoch_depths=[]
    t0 = time.time()
    for xb, yb in tqdm(train_loader, desc=f"Epoch {epoch}"):
        xb, yb = xb.to(device), yb.to(device)
        B = xb.size(0)
        with torch.no_grad(): emb = model.encoder(xb)
        obs = torch.cat([emb, torch.zeros(B,1,device=device)], dim=1)

        logits, values = controller(obs)
        probs = F.softmax(logits, dim=1)
        depths_idx = torch.multinomial(probs, num_samples=1).squeeze(1)
        depths = depths_idx + 1

        # log depth histogram
        if epoch not in depth_hist_per_epoch:
            depth_hist_per_epoch[epoch]=[]
        depth_hist_per_epoch[epoch].extend(depths.cpu().numpy().tolist())

        # forward/backward
        preds = model.forward_depths(xb, depths)
        losses = ce_loss(preds, yb)
        model_opt.zero_grad(); losses.mean().backward(); model_opt.step()

        with torch.no_grad():
            accs = compute_accuracy(preds, yb)
            rewards = accs - args["lambda_compute"]*(depths.float()/args["max_depth"])
        rewards_t = rewards.to(device).float()

        # PPO-style update
        old_logits = logits.detach(); old_probs = F.softmax(old_logits, dim=1)
        old_log_probs = torch.log(torch.gather(old_probs,1,depths_idx.unsqueeze(1)).squeeze(1)+1e-10)
        advantages = rewards_t - values.detach()
        for _ in range(args["ppo_epochs"]):
            logits_new, values_new = controller(obs)
            probs_new = F.softmax(logits_new, dim=1)
            logp_new = torch.log(torch.gather(probs_new,1,depths_idx.unsqueeze(1)).squeeze(1)+1e-10)
            ratio = torch.exp(logp_new - old_log_probs)
            surr1 = ratio*advantages
            surr2 = torch.clamp(ratio,1-args["clip_eps"],1+args["clip_eps"])*advantages
            policy_loss = -torch.mean(torch.min(surr1,surr2))
            value_loss = F.mse_loss(values_new,rewards_t)
            entropy = -torch.mean(torch.sum(probs_new*torch.log(probs_new+1e-10),dim=1))
            loss = policy_loss + args["vf_coef"]*value_loss - args["ent_coef"]*entropy
            controller_opt.zero_grad(); loss.backward(); controller_opt.step()

        epoch_rewards.append(float(rewards_t.mean().item()))
        epoch_depths.append(float(depths.float().mean().item()))

    # Eval
    model.eval(); controller.eval()
    def eval_loader(loader):
        tot=0; n=0; depth_sum=0.0
        with torch.no_grad():
            for xb, yb in loader:
                xb, yb = xb.to(device), yb.to(device)
                B = xb.size(0)
                emb = model.encoder(xb)
                obs = torch.cat([emb, torch.zeros(B,1,device=device)], dim=1)
                logits,_ = controller(obs)
                probs = F.softmax(logits, dim=1)
                depth_idx = probs.argmax(dim=1); depths = depth_idx+1
                preds = model.forward_depths(xb, depths)
                tot += (preds.argmax(dim=1) == yb).sum().item()
                n += B; depth_sum += depths.float().sum().item()
        return tot/n, depth_sum/n
    train_acc, avg_depth_train = eval_loader(train_loader)
    test_acc, avg_depth_test = eval_loader(test_loader)

    # logging
    epochs_list.append(epoch); train_acc_list.append(train_acc); test_acc_list.append(test_acc)
    avg_depth_train_list.append(avg_depth_train); avg_depth_test_list.append(avg_depth_test)
    reward_list.append(sum(epoch_rewards)/len(epoch_rewards) if len(epoch_rewards)>0 else 0.0)

    print(f"Epoch {epoch} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | Avg depth train: {avg_depth_train:.2f} | Avg depth test: {avg_depth_test:.2f} | Avg reward: {reward_list[-1]:.4f} | epoch time: {time.time()-t0:.2f}s")

# ----------------- Plotting -----------------
# Accuracy
plt.figure(); plt.plot(epochs_list, train_acc_list, 'o-'); plt.plot(epochs_list, test_acc_list, 'o-')
plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Accuracy vs Epoch'); plt.legend(['Train','Test']); plt.grid(True); plt.show()
# Avg depth
plt.figure(); plt.plot(epochs_list, avg_depth_train_list, 'o-'); plt.plot(epochs_list, avg_depth_test_list, 'o-')
plt.xlabel('Epoch'); plt.ylabel('Avg Depth'); plt.title('Avg Depth vs Epoch'); plt.legend(['Train','Test']); plt.grid(True); plt.show()
# Reward
plt.figure(); plt.plot(epochs_list, reward_list, 'o-'); plt.xlabel('Epoch'); plt.ylabel('Avg Reward'); plt.title('Avg Reward vs Epoch'); plt.grid(True); plt.show()
# Depth histograms per epoch
for e in depth_hist_per_epoch:
    plt.figure(); plt.hist(depth_hist_per_epoch[e], bins=np.arange(1,args["max_depth"]+2)-0.5)
    plt.xlabel('Depth'); plt.ylabel('Count'); plt.title(f'Depth histogram epoch {e}'); plt.grid(True); plt.show()

# The following script provides a real-time comparison of the complexity
# of the Adaptive, Static, and AutoML architectures by measuring their
# parameter count (space complexity) and inference time (time complexity).

import torch
import torch.nn as nn
import torch.nn.functional as F
import time
from tabulate import tabulate
import matplotlib.pyplot as plt

# -------------------- Your Project: Adaptive Neural Architecture --------------------
# Core Idea: A Reinforcement Learning controller decides how many recurrent core blocks to use per sample.
# This makes it highly efficient during inference.

# Encoder: Transforms the input image into a fixed-size feature vector.
class Encoder(nn.Module):
    def __init__(self, in_channels, hidden_dim):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(128, hidden_dim)
    def forward(self, x):
        return self.fc(self.conv(x).view(x.size(0), -1))

# Ramanujan Core Block: A recurrent, residual-like block.
class RamanujanCoreBlock(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.fc1 = nn.Linear(hidden_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, hidden_dim)
    def forward(self, x):
        return F.relu(self.fc2(F.relu(self.fc1(x)))) + x

# Predictor: A simple linear layer for the final classification.
class Predictor(nn.Module):
    def __init__(self, hidden_dim, num_classes):
        super().__init__()
        self.fc = nn.Linear(hidden_dim, num_classes)
    def forward(self, x):
        return self.fc(x)

# Controller: An Actor-Critic RL agent that decides the depth.
class Controller(nn.Module):
    def __init__(self, hidden_dim, max_depth):
        super().__init__()
        self.actor = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, max_depth + 1)
        )
        self.critic = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, 1)
        )
    def forward(self, x):
        return self.actor(x), self.critic(x)

# Adaptive Model: The complete, dynamic network.
class AdaptiveModel(nn.Module):
    def __init__(self, in_channels, num_classes, hidden_dim, max_depth):
        super().__init__()
        self.max_depth = max_depth
        self.encoder = Encoder(in_channels, hidden_dim)
        self.core_block = RamanujanCoreBlock(hidden_dim)
        self.predictor = Predictor(hidden_dim, num_classes)
        self.controller = Controller(hidden_dim, max_depth)
    def forward(self, x):
        encoded_x = self.encoder(x)
        features = encoded_x
        action, value = self.controller(features)

        depth_dist = F.softmax(action, dim=-1)
        depth = torch.argmax(depth_dist, dim=-1)

        for d in range(self.max_depth):
            mask = (d < depth).float().unsqueeze(1)
            features = features + mask * (self.core_block(features) - features)

        output = self.predictor(features)
        return output, depth_dist, value

# -------------------- A Fixed-Depth Static CNN Model --------------------
# Core Idea: All layers are applied to all samples, regardless of complexity.
class StaticCNN(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.AdaptiveAvgPool2d((1,1))
        )
        self.classifier = nn.Sequential(
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )
    def forward(self, x):
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)
        return self.classifier(x)

# -------------------- Conceptual AutoML (NAS) Model --------------------
# Core Idea: An offline search process finds the best static architecture.
class FoundNASModel(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.found_layers = nn.Sequential(
            nn.Conv2d(3, 16, 3, padding=1),
            nn.ReLU(),
            nn.Conv2d(16, 32, 5, padding=2),
            nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(32 * 16 * 16, 512), # Corrected input size after MaxPool2d
            nn.ReLU(),
            nn.Linear(512, num_classes)
        )
    def forward(self, x):
        return self.found_layers(x)

# -------------------- Complexity Comparison Function --------------------

def compare_models():
    # Model parameters for comparison
    in_channels = 3
    num_classes = 10
    hidden_dim = 256
    max_depth = 5
    batch_size = 128

    # Initialize models
    adaptive_model = AdaptiveModel(in_channels, num_classes, hidden_dim, max_depth)
    static_model = StaticCNN(in_channels, num_classes)
    nas_model = FoundNASModel(num_classes)

    models = {
        'Adaptive (Your Project)': adaptive_model,
        'Static CNN': static_model,
        'AutoML (Conceptual)': nas_model
    }

    results = []

    # Generate a dummy input tensor
    dummy_input = torch.randn(batch_size, in_channels, 32, 32)

    print("Starting complexity comparison...")

    for name, model in models.items():
        # --- Space Complexity (Parameter Count) ---
        param_count = sum(p.numel() for p in model.parameters() if p.requires_grad)

        # --- Time Complexity (Inference Time) ---
        # Warm-up run
        for _ in range(10):
            with torch.no_grad():
                model(dummy_input)

        # Timed run
        start_time = time.time()
        for _ in range(100):
            with torch.no_grad():
                model(dummy_input)
        end_time = time.time()
        avg_time_ms = ((end_time - start_time) / 100) * 1000

        # Adjust time for AdaptiveModel to reflect per-sample decisions
        if name == 'Adaptive (Your Project)':
            # Assume an average depth of 2 out of max_depth=5 for simplicity in this demo.
            # This is a key benefit of the adaptive model, as shown in your paper.
            # This time adjustment logic is commented out as we're measuring total inference time here.
            pass # time_per_sample_adjusted = avg_time_ms / batch_size
        # else:
            # time_per_sample_adjusted = avg_time_ms / batch_size

        results.append([name, param_count, avg_time_ms])

    print("\n" + tabulate(results, headers=["Model", "Parameter Count", "Inference Time (ms)"], tablefmt="grid"))

    # --- Plotting the Results ---
    model_names = [res[0] for res in results]
    params = [res[1] / 1e6 for res in results] # Convert to Millions
    times = [res[2] for res in results]

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))

    # Plot 1: Parameter Count (Space Complexity)
    ax1.bar(model_names, params, color=['blue', 'gray', 'green'])
    ax1.set_title('Model Size (Parameter Count)')
    ax1.set_ylabel('Millions of Parameters')
    ax1.grid(True, axis='y')

    # Plot 2: Inference Time (Time Complexity)
    ax2.bar(model_names, times, color=['blue', 'gray', 'green'])
    ax2.set_title('Total Inference Time (100 batches)')
    ax2.set_ylabel('Time (milliseconds)')
    ax2.grid(True, axis='y')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    compare_models()

#!/usr/bin/env python3
# real_adaptive_comparison.py
# A proper comparison of Adaptive Depth, Static, and NAS-inspired models

import torch
import torch.nn as nn
import torch.nn.functional as F
import time
import numpy as np
from tabulate import tabulate
import matplotlib.pyplot as plt

class RamanujanCoreBlock(nn.Module):
    def __init__(self, dim):
        super().__init__()
        self.fc1 = nn.Linear(dim, dim)
        self.fc2 = nn.Linear(dim, dim)
        self.alpha = nn.Parameter(torch.tensor(0.5))

    def forward(self, h):
        r = F.relu(self.fc1(h))
        r = self.fc2(r)
        return (1 - torch.sigmoid(self.alpha)) * h + torch.sigmoid(self.alpha) * (h + r)

class EncoderConv(nn.Module):
    def __init__(self, hidden_dim):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))
        )
        self.fc = nn.Linear(128, hidden_dim)

    def forward(self, x):
        h = self.conv(x).view(x.size(0), -1)
        return F.relu(self.fc(h))

# TRUE ADAPTIVE MODEL - actually varies computation per sample
class TrueAdaptiveModel(nn.Module):
    def __init__(self, hidden_dim, num_classes, max_depth=5):
        super().__init__()
        self.encoder = EncoderConv(hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(max_depth)])
        self.predictor = nn.Linear(hidden_dim, num_classes)
        self.max_depth = max_depth

    def forward_with_depths(self, x, depths):
        """Forward pass where each sample uses specified depth"""
        batch_size = x.size(0)
        h = self.encoder(x)

        # Process each sample with its specified depth
        outputs = []
        actual_flops = 0

        for i in range(batch_size):
            hi = h[i:i+1]  # Single sample
            depth = int(depths[i].item())

            # Apply only the required number of blocks
            for j in range(depth):
                hi = self.core_blocks[j](hi)
                actual_flops += hi.numel() * 2  # Rough FLOP counting

            outputs.append(self.predictor(hi).squeeze(0))

        return torch.stack(outputs, dim=0), actual_flops

# STATIC MODEL - fixed computation for all samples
class StaticModel(nn.Module):
    def __init__(self, hidden_dim, num_classes, depth=5):
        super().__init__()
        self.encoder = EncoderConv(hidden_dim)
        self.core_blocks = nn.ModuleList([RamanujanCoreBlock(hidden_dim) for _ in range(depth)])
        self.predictor = nn.Linear(hidden_dim, num_classes)
        self.depth = depth

    def forward(self, x):
        h = self.encoder(x)
        actual_flops = 0

        # Always apply all blocks to all samples
        for block in self.core_blocks:
            h = block(h)
            actual_flops += h.numel() * 2

        return self.predictor(h), actual_flops

# NAS-INSPIRED MODEL - represents a found efficient architecture
class NASInspiredModel(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        # Inspired by EfficientNet-like architectures with varied depths
        self.stem = nn.Sequential(
            nn.Conv2d(3, 32, 3, stride=2, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True)
        )

        # Mobile inverted bottleneck blocks (MBConv-like)
        self.blocks = nn.Sequential(
            self._make_mbconv_block(32, 64, 3, 1, 2),
            self._make_mbconv_block(64, 96, 3, 6, 2),
            self._make_mbconv_block(96, 160, 5, 6, 2),
            self._make_mbconv_block(160, 320, 3, 6, 1),
        )

        self.head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(320, num_classes)
        )

    def _make_mbconv_block(self, in_ch, out_ch, kernel_size, expand_ratio, stride):
        hidden_ch = in_ch * expand_ratio
        return nn.Sequential(
            # Expansion
            nn.Conv2d(in_ch, hidden_ch, 1) if expand_ratio != 1 else nn.Identity(),
            nn.BatchNorm2d(hidden_ch) if expand_ratio != 1 else nn.Identity(),
            nn.ReLU(inplace=True) if expand_ratio != 1 else nn.Identity(),
            # Depthwise
            nn.Conv2d(hidden_ch, hidden_ch, kernel_size, stride, kernel_size//2, groups=hidden_ch),
            nn.BatchNorm2d(hidden_ch),
            nn.ReLU(inplace=True),
            # Pointwise
            nn.Conv2d(hidden_ch, out_ch, 1),
            nn.BatchNorm2d(out_ch)
        )

    def forward(self, x):
        h = self.stem(x)
        h = self.blocks(h)
        return self.head(h), h.numel() * 8  # Rough FLOP estimate

def run_comprehensive_comparison():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Running comparison on: {device}")

    # Parameters
    batch_size = 64
    hidden_dim = 256
    num_classes = 10
    max_depth = 5

    # Create models
    adaptive_model = TrueAdaptiveModel(hidden_dim, num_classes, max_depth).to(device)
    static_model = StaticModel(hidden_dim, num_classes, max_depth).to(device)
    nas_model = NASInspiredModel(num_classes).to(device)

    # Test inputs
    dummy_input = torch.randn(batch_size, 3, 32, 32).to(device)

    # Simulate adaptive depths (realistic distribution)
    # Most samples use shallow depths, some need deeper processing
    adaptive_depths = torch.tensor(np.random.choice([1, 2, 3, 4, 5],
                                                   size=(batch_size,),
                                                   p=[0.3, 0.4, 0.2, 0.08, 0.02])).to(device)

    results = []

    # 1. ADAPTIVE MODEL ANALYSIS
    print("\n=== ADAPTIVE MODEL ===")
    adaptive_model.eval()
    with torch.no_grad():
        # Warm up
        for _ in range(10):
            _ = adaptive_model.forward_with_depths(dummy_input, adaptive_depths)

        # Timing
        start_time = time.time()
        total_flops = 0
        for _ in range(100):
            _, flops = adaptive_model.forward_with_depths(dummy_input, adaptive_depths)
            total_flops += flops
        end_time = time.time()

        adaptive_time = (end_time - start_time) / 100 * 1000  # ms
        adaptive_flops = total_flops / 100
        adaptive_params = sum(p.numel() for p in adaptive_model.parameters())
        avg_depth = adaptive_depths.float().mean().item()

    results.append(['Adaptive (Variable Depth)', adaptive_params, adaptive_time,
                   adaptive_flops, f"{avg_depth:.2f}"])

    # 2. STATIC MODEL ANALYSIS
    print("=== STATIC MODEL ===")
    static_model.eval()
    with torch.no_grad():
        # Warm up
        for _ in range(10):
            _ = static_model(dummy_input)

        # Timing
        start_time = time.time()
        total_flops = 0
        for _ in range(100):
            _, flops = static_model(dummy_input)
            total_flops += flops
        end_time = time.time()

        static_time = (end_time - start_time) / 100 * 1000  # ms
        static_flops = total_flops / 100
        static_params = sum(p.numel() for p in static_model.parameters())

    results.append(['Static (Fixed Depth=5)', static_params, static_time,
                   static_flops, "5.00"])

    # 3. NAS MODEL ANALYSIS
    print("=== NAS-INSPIRED MODEL ===")
    nas_model.eval()
    with torch.no_grad():
        # Warm up
        for _ in range(10):
            _ = nas_model(dummy_input)

        # Timing
        start_time = time.time()
        total_flops = 0
        for _ in range(100):
            _, flops = nas_model(dummy_input)
            total_flops += flops
        end_time = time.time()

        nas_time = (end_time - start_time) / 100 * 1000  # ms
        nas_flops = total_flops / 100
        nas_params = sum(p.numel() for p in nas_model.parameters())

    results.append(['NAS-Inspired (EfficientNet-like)', nas_params, nas_time,
                   nas_flops, "N/A"])

    # DISPLAY RESULTS
    print("\n" + "="*80)
    print("COMPREHENSIVE MODEL COMPARISON")
    print("="*80)
    print(tabulate(results,
                   headers=["Model Type", "Parameters", "Time (ms)", "FLOPs", "Avg Depth"],
                   tablefmt="grid",
                   floatfmt=".2f"))

    # EFFICIENCY ANALYSIS
    print(f"\n=== EFFICIENCY ANALYSIS ===")
    print(f"Adaptive vs Static:")
    print(f"  - Speed improvement: {static_time/adaptive_time:.2f}x faster")
    print(f"  - FLOP reduction: {static_flops/adaptive_flops:.2f}x fewer operations")
    print(f"  - Parameter overhead: {(adaptive_params-static_params)/static_params*100:.1f}% more params")

    print(f"\nAdaptive vs NAS:")
    print(f"  - Speed comparison: {nas_time/adaptive_time:.2f}x (NAS/Adaptive)")
    print(f"  - FLOP comparison: {nas_flops/adaptive_flops:.2f}x (NAS/Adaptive)")
    print(f"  - Parameter comparison: {nas_params/adaptive_params:.2f}x (NAS/Adaptive)")

    # VISUALIZATION
    model_names = [r[0] for r in results]
    params = [r[1]/1e6 for r in results]  # Convert to millions
    times = [r[2] for r in results]
    flops = [r[3]/1e6 for r in results]   # Convert to millions

    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))

    # Parameters
    ax1.bar(range(len(model_names)), params, color=['blue', 'red', 'green'])
    ax1.set_title('Model Size (Parameters)')
    ax1.set_ylabel('Million Parameters')
    ax1.set_xticks(range(len(model_names)))
    ax1.set_xticklabels([name.split()[0] for name in model_names])
    ax1.grid(True, alpha=0.3)

    # Inference Time
    ax2.bar(range(len(model_names)), times, color=['blue', 'red', 'green'])
    ax2.set_title('Inference Time')
    ax2.set_ylabel('Milliseconds')
    ax2.set_xticks(range(len(model_names)))
    ax2.set_xticklabels([name.split()[0] for name in model_names])
    ax2.grid(True, alpha=0.3)

    # FLOPs
    ax3.bar(range(len(model_names)), flops, color=['blue', 'red', 'green'])
    ax3.set_title('Computational Cost (FLOPs)')
    ax3.set_ylabel('Million FLOPs')
    ax3.set_xticks(range(len(model_names)))
    ax3.set_xticklabels([name.split()[0] for name in model_names])
    ax3.grid(True, alpha=0.3)

    # Efficiency scatter plot (FLOPs vs Time)
    ax4.scatter(flops, times, c=['blue', 'red', 'green'], s=100)
    for i, name in enumerate(model_names):
        ax4.annotate(name.split()[0], (flops[i], times[i]),
                    xytext=(5, 5), textcoords='offset points')
    ax4.set_xlabel('Million FLOPs')
    ax4.set_ylabel('Inference Time (ms)')
    ax4.set_title('Efficiency: FLOPs vs Time')
    ax4.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.show()

    return results

if __name__ == "__main__":
    results = run_comprehensive_comparison()